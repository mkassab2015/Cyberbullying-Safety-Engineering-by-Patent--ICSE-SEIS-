abstract,cleaned_abstract,topic
"A method for identifying cyberbullying may include obtaining content from a first electronic device associated with a first user; identifying, using a machine learning model, the cyberbullying of the first user based on the content obtained from the first electronic device; and providing anonymized information related to the cyberbullying to a second electronic device associated with a second user",method identifying cyberbullying may include obtaining content first electronic device associated first user identifying using machine learning model cyberbullying first user based content obtained first electronic device providing anonymized information related cyberbullying second electronic device associated second user,0
"A method of determining a risk of cyberbullying in accordance with the present disclosure may include electronically intercepting an outgoing electronic communication at a source of the outgoing electronic communication. The method may additionally include determining a cyberbullying risk score for the outgoing electronic communication, the cyberbullying risk score based at least on content of the outgoing electronic communication, user history of a user sending the outgoing electronic communication, and a third party policy. The method may also include, in response to the cyberbullying risk score exceeding a threshold, providing a recommended course of action to the user sending the outgoing electronic communication.",method determining risk cyberbullying accordance present disclosure may include electronically intercepting outgoing electronic communication source outgoing electronic communication method may additionally include determining cyberbullying risk score outgoing electronic communication cyberbullying risk score based least content outgoing electronic communication user history user sending outgoing electronic communication third party policy method may also include response cyberbullying risk score exceeding threshold providing recommended course action user sending outgoing electronic communication,0
"A server for storing and managing online threat data according to an embodiment of the present disclosure includes: an online threat data collection unit that collects online threat data from an online threat data providing server, an online threat data analysis unit that analyzes the online threat data to extract an online threat string, and uses the online threat string as an index to generate information for retrieving the online threat data; and a database in which information generated by the online threat data analysis unit is stored.",server storing managing online threat data according embodiment present disclosure includes online threat data collection unit collect online threat data online threat data providing server online threat data analysis unit analyzes online threat data extract online threat string us online threat string index generate information retrieving online threat data database information generated online threat data analysis unit stored,2
"A machine learning-based method for accelerating a generation of automated fraud or abuse detection workflows in a digital threat mitigation platform includes identifying a plurality of distinct digital event features indicative of digital fraud; automatically deriving a plurality of distinct digital event decisioning criteria based on the plurality of distinct digital event features and a digital event data corpus associated with a target subscriber; automatically constructing a probationary automated fraud or abuse detection workflow based on the plurality of distinct digital event decisioning criteria, and deploying the probationary automated fraud or abuse detection workflow to a target digital fraud prevention environment associated with the target subscriber.",machine learningbased method accelerating generation automated fraud abuse detection workflow digital threat mitigation platform includes identifying plurality distinct digital event feature indicative digital fraud automatically deriving plurality distinct digital event decisioning criterion based plurality distinct digital event feature digital event data corpus associated target subscriber automatically constructing probationary automated fraud abuse detection workflow based plurality distinct digital event decisioning criterion deploying probationary automated fraud abuse detection workflow target digital fraud prevention environment associated target subscriber,2
"Additional background information is used with a trained neural network based model to help classify whether text is a subtly and/or ambiguously offensive. This additional background information can come from different sources such as the article on which the comment was made, world knowledge about the external entities (e.g., Wikipedia, Urban Dictionary), phrases referenced in the text being classified, and, the context of the previous comments/text in the thread. The background information is retrieved based on key entities (e.g., people, places things) and/or key phrases in the comment. Sentence matrix encodings are built for both the comment and the background information. The background information encoding is used to condition the comment encoding. The background information encoding, and the conditioned comment encoding are fed to a trained multi-level perceptron to classify the comment as hate speech or non-hate speech.",additional background information used trained neural network based model help classify whether text subtly andor ambiguously offensive additional background information come different source article comment made world knowledge external entity wikipedia urban dictionary phrase referenced text classified context previous commentstext thread background information retrieved based key entity people place thing andor key phrase comment sentence matrix encoding built comment background information background information encoding used condition comment encoding background information encoding conditioned comment encoding fed trained multilevel perceptron classify comment hate speech nonhate speech,0
"The disclosure discloses a cyberbullying detection method and system. The detection method includes: obtaining a to-be-detected data set, where the to-be-detected data set includes multiple sentence texts of multiple users; classifying the to-be-detected data set by using a classification model based on a bidirectional recurrent neural network, to obtain a probability that each sentence text belongs to cyberbullying; obtaining a sentence text whose probability of belonging to cyberbullying is greater than a specified probability, to obtain a first sentence text set; obtaining an attention value of each sentence text in the first sentence text set and an attention value of each user; detecting, according to the attention value of each sentence text in the first sentence text set and the attention value of each user, whether each sentence text belongs to cyberbullying. The disclosure can achieve a good text classification and identification effect, high accuracy, and a low loss rate.",disclosure discloses cyberbullying detection method system detection method includes obtaining tobedetected data set tobedetected data set includes multiple sentence text multiple user classifying tobedetected data set using classification model based bidirectional recurrent neural network obtain probability sentence text belongs cyberbullying obtaining sentence text whose probability belonging cyberbullying greater specified probability obtain first sentence text set obtaining attention value sentence text first sentence text set attention value user detecting according attention value sentence text first sentence text set attention value user whether sentence text belongs cyberbullying disclosure achieve good text classification identification effect high accuracy low loss rate,0
"A harassment detection apparatus includes: an executing unit configured to execute a session of a shared environment; an input unit configured to receive biometric data, the biometric data being associated with a plurality of users participating in the executed session of the shared environment; a generating unit configured to generate, based on at least a part of the biometric data, emotion data associated with the plurality of users, the emotion data comprising a valence value and/or an arousal value associated with each of the plurality of users; a detection unit configured to detect, responsive to at least a first part of the emotion data satisfying one or more of a first set of criteria, one or more first users associated with the at least first part of the emotion data; and a modifying unit configured to modify, responsive to the detection of the one or more first users, one or more aspects of the shared environment.",harassment detection apparatus includes executing unit configured execute session shared environment input unit configured receive biometric data biometric data associated plurality user participating executed session shared environment generating unit configured generate based least part biometric data emotion data associated plurality user emotion data comprising valence value andor arousal value associated plurality user detection unit configured detect responsive least first part emotion data satisfying one first set criterion one first user associated least first part emotion data modifying unit configured modify responsive detection one first user one aspect shared environment,-1
"According to an embodiment of the present disclosure, a server for providing online threat data based on user-customized keywords includes: an online threat data collection unit that accesses a channel of a messenger program and collects channel- specific online threat data; an online threat database construction unit that analyzes the online threat data to extract a string, uses the string as an index to generate information for retrieving the online threat data, and stores the generated information in a channel- specific database; when the user-customized keywords and user identifiers are received from a user terminal through a user-customized keyword registration procedure, a user-customized keyword database construction unit that matches the user-customized keywords with the user identifiers and stores the matched user-customized keywords and user identifiers in a user-customized keyword database; and when the user terminal logs in using the user identifiers, an online threat data providing unit that extracts a pre-registered user-customized keyword corresponding to the user identifier from the user-customized keyword database, extracts the channel-specific online threat data corresponding to the user-customized keywords from the channel-specific database, and provides the extracted online threat data to the user terminal.",according embodiment present disclosure server providing online threat data based usercustomized keywords includes online threat data collection unit access channel messenger program collect channel specific online threat data online threat database construction unit analyzes online threat data extract string us string index generate information retrieving online threat data store generated information channel specific database usercustomized keywords user identifier received user terminal usercustomized keyword registration procedure usercustomized keyword database construction unit match usercustomized keywords user identifier store matched usercustomized keywords user identifier usercustomized keyword database user terminal log using user identifier online threat data providing unit extract preregistered usercustomized keyword corresponding user identifier usercustomized keyword database extract channelspecific online threat data corresponding usercustomized keywords channelspecific database provides extracted online threat data user terminal,2
"A system for preventing cyberbullying is disclosed. An input message analysis module (110) receives an input message of a multilingual format from a sender, pre-process the input message by using a tokenization technique for splitting the input message into one or more tokens, identifies a context and content associated with the one or more tokens, analyzes sentiment associated with the one or more tokens. A message categorization module (120) employs the trained machine learning model to detect presence of one or more offensive keywords within the input message when the input message is categorized as a harmful message category. A message modification recommendation module (130) generates alert for preventing a recipient from the cyberbullying, recommends one or more substitute words associated with the one or more offensive keywords to the sender for modification of the content of the input message. A sender grading module (140) calculates a score corresponding to a sender's decision correlated with the one or more substitute words.",system preventing cyberbullying disclosed input message analysis module receives input message multilingual format sender preprocess input message using tokenization technique splitting input message one token identifies context content associated one token analyzes sentiment associated one token message categorization module employ trained machine learning model detect presence one offensive keywords within input message input message categorized harmful message category message modification recommendation module generates alert preventing recipient cyberbullying recommends one substitute word associated one offensive keywords sender modification content input message sender grading module calculates score corresponding sender decision correlated one substitute word,0
"In some cases, one or more heuristics can be automatically generated using a small dataset of segments previously labeled by one or more domain experts. The generated one or more heuristics along with one or more patterns can be used to assign training labels to a large unlabeled dataset of segments. A subset of segments representing an occurrence of verbal harassment can be selected using the assigned training labels. Randomly selected segments can be used as being indicative of a non-occurrence of verbal harassment. The selected subset of segments and randomly selected segments can be used to train one or more machine learning models for verbal harassment detection.",case one heuristic automatically generated using small dataset segment previously labeled one domain expert generated one heuristic along one pattern used assign training label large unlabeled dataset segment subset segment representing occurrence verbal harassment selected using assigned training label randomly selected segment used indicative nonoccurrence verbal harassment selected subset segment randomly selected segment used train one machine learning model verbal harassment detection,0
"A computer-implemented framework and/or system for cyberbullying detection is disclosed. The system includes two main components: (1) A representation learning network that encodes the social media session by exploiting multi-modal features, e.g., text, network, and time; and (2) a multi-task learning network that simultaneously fits the comment inter-arrival times and estimates the bullying likelihood based on a Gaussian Mixture Model. The system jointly optimizes the parameters of both components to overcome the shortcomings of decoupled training. The system includes an unsupervised cyberbullying detection model that not only experimentally outperforms the state-of-the-art unsupervised models, but also achieves competitive performance compared to supervised models.",computerimplemented framework andor system cyberbullying detection disclosed system includes two main component representation learning network encodes social medium session exploiting multimodal feature text network time multitask learning network simultaneously fit comment interarrival time estimate bullying likelihood based gaussian mixture model system jointly optimizes parameter component overcome shortcoming decoupled training system includes unsupervised cyberbullying detection model experimentally outperforms stateoftheart unsupervised model also achieves competitive performance compared supervised model,0
"An abuser detection method, apparatus, system, and/or non-transitory computer readable medium may decrease and/or prevent an occurrence of abuse by detecting an abuser based on features of users of a service and imposing a restriction on the abuser before the abuse occurs.",abuser detection method apparatus system andor nontransitory computer readable medium may decrease andor prevent occurrence abuse detecting abuser based feature user service imposing restriction abuser abuse occurs,1
"In some cases, a verbal harassment detection system may use machine learning models to detect verbal harassment in real-time or near real-time. The system may receive an audio segment comprising a portion of audio captured by a microphone located within a vehicle. Further, the system may convert the audio segment to a text segment. The system may provide at least the text segment to a prediction model associated with verbal harassment detection to obtain a harassment prediction. Further, the system may provide the audio segment to an emotion detector to obtain a detected emotion of a speaking user that made an utterance included in the audio segment. Based at least in part on the harassment prediction and the detected emotion, the system may automatically, and without user intervention, determine whether a user is being harassed.",case verbal harassment detection system may use machine learning model detect verbal harassment realtime near realtime system may receive audio segment comprising portion audio captured microphone located within vehicle system may convert audio segment text segment system may provide least text segment prediction model associated verbal harassment detection obtain harassment prediction system may provide audio segment emotion detector obtain detected emotion speaking user made utterance included audio segment based least part harassment prediction detected emotion system may automatically without user intervention determine whether user harassed,-1
"A system and method are provided for generating a trained model to filter data sets for filtering hate speech. The method includes obtaining an unfiltered corpus of data, obtaining a set of trigger phrases, and using the set of trigger phrases to generate a trained model which comprises at least one conditional likelihood of the trigger phrases conditioned on documents in the corpus of data. A system and method are also provided for filtering data sets for hate speech using pre-trained models. The method includes obtaining a pretrained model generated using a set of trigger phrases and which comprises at least one conditional likelihood of the trigger phrases conditioned on document in a corpus of data used to generate the pretrained model; using the pretrained model to filter an unfiltered dataset and generate a filtered dataset; and outputting the filtered dataset.",system method provided generating trained model filter data set filtering hate speech method includes obtaining unfiltered corpus data obtaining set trigger phrase using set trigger phrase generate trained model comprises least one conditional likelihood trigger phrase conditioned document corpus data system method also provided filtering data set hate speech using pretrained model method includes obtaining pretrained model generated using set trigger phrase comprises least one conditional likelihood trigger phrase conditioned document corpus data used generate pretrained model using pretrained model filter unfiltered dataset generate filtered dataset outputting filtered dataset,0
"A technique is provided for detecting whether consumer abuse has occurred in an electronic device. In accordance with this technique, a system is provided for detecting the occurrence of a consumer abuse event and storing a record thereof. In one embodiment, the system provides one or more sensors coupled to an abuse detection circuitry for detecting the occurrence of an abuse event. The system may further provide a memory, wherein upon detecting an abuse event, the abuse detection circuitry may store a record of the abuse event into the memory. The system may further provide an interface by which a diagnostic device may access the memory and analyze the abuse event records to determine if an abuse event occurred in the electronic device.",technique provided detecting whether consumer abuse occurred electronic device accordance technique system provided detecting occurrence consumer abuse event storing record thereof one embodiment system provides one sensor coupled abuse detection circuitry detecting occurrence abuse event system may provide memory wherein upon detecting abuse event abuse detection circuitry may store record abuse event memory system may provide interface diagnostic device may access memory analyze abuse event record determine abuse event occurred electronic device,1
"A scale incorporating an abuse detection and recordal system has a scale for weighing an article placed thereon, the scale defining a surface adapted to support the article thereon and a component damageable by an excessive force downwardly directed on the support surface. A frangible layer is disposed on the support surface and frangible by a downwardly directed force less than the excessive force required to damage the component, whereby the frangible layer acts as an abuse detection and recordal system to detect and record the use of such force.",scale incorporating abuse detection recordal system scale weighing article placed thereon scale defining surface adapted support article thereon component damageable excessive force downwardly directed support surface frangible layer disposed support surface frangible downwardly directed force less excessive force required damage component whereby frangible layer act abuse detection recordal system detect record use force,1
"An account abuse detection or prevention device, a data collection device, and an account abuse detection or prevention program, which are capable of promptly detecting or preventing abuse of an account. An account abuse detection device (6) includes an access-amount-related value information receiving unit (11) and a detection unit (12). The access-amount-related value information receiving unit (11) receives access-amount-related value information from a management device (3). The management device (3) manages a specific account. The specific account is used when transmitting data from a plurality of data transmission devices (2) to a data collection device (5) via a public network. Access-amount-related value information is related to an access-amount-related value. The access-amount-related value is related to the amount of access by the public network (4) through the account. The detection unit (12) compares the access-amount-related value to a predetermined threshold value to detect abuse of the account.",account abuse detection prevention device data collection device account abuse detection prevention program capable promptly detecting preventing abuse account account abuse detection device includes accessamountrelated value information receiving unit detection unit accessamountrelated value information receiving unit receives accessamountrelated value information management device management device manages specific account specific account used transmitting data plurality data transmission device data collection device via public network accessamountrelated value information related accessamountrelated value accessamountrelated value related amount access public network account detection unit compare accessamountrelated value predetermined threshold value detect abuse account,1
"A system for detecting abusive operation of transport refrigeration units (28) is provided. The system includes a storage device (80) to store abuse parameters associated with a transport refrigeration unit (28). Also included is an abuse detection system coupled to the storage device, the abuse detection system including: a diagnostic module (92) to determine the occurrence of abusive operation of the transport refrigeration unit in response to the abuse parameters; a failure probability module (94) to determine a probability of failure for at least one component of the transport refrigeration unit in response to the abuse parameters; and a life extending module (96) to determine adjustments in the operation of at least one component of the transport refrigeration unit in response to the probability of failure.",system detecting abusive operation transport refrigeration unit provided system includes storage device store abuse parameter associated transport refrigeration unit also included abuse detection system coupled storage device abuse detection system including diagnostic module determine occurrence abusive operation transport refrigeration unit response abuse parameter failure probability module determine probability failure least one component transport refrigeration unit response abuse parameter life extending module determine adjustment operation least one component transport refrigeration unit response probability failure,1
"An online service abuser detection method, apparatus, system, and/or non-transitory computer readable medium may decrease and/or prevent an occurrence of abuse by users of an online service by detecting an abuser based on features of users of the online service and imposing a restriction on the abuser before the abuse is transmitted to the other users of the online service.",online service abuser detection method apparatus system andor nontransitory computer readable medium may decrease andor prevent occurrence abuse user online service detecting abuser based feature user online service imposing restriction abuser abuse transmitted user online service,1
"Some embodiments use text and/or image processing methods to determine whether a user of an electronic messaging platform is subject to an online threat such as cyberbullying, sexual grooming, and identity theft, among others. In some embodiments, a text content of electronic messages is automatically harvested and aggregated into conversations. Conversation data are then analyzed to extract various threat indicators. A result of a text analysis may be combined with a result of an analysis of an image transmitted as part of the respective conversation. When a threat is detected, some embodiments automatically send a notification to a third party (e.g., parent, teacher, etc.)",embodiment use text andor image processing method determine whether user electronic messaging platform subject online threat cyberbullying sexual grooming identity theft among others embodiment text content electronic message automatically harvested aggregated conversation conversation data analyzed extract various threat indicator result text analysis may combined result analysis image transmitted part respective conversation threat detected embodiment automatically send notification third party parent teacher etc,-1
"Cyberbullying may be mitigated by intercepting and accurately analyzing the sentiment of the social media messages before presenting them to the intended recipient device. Based on the sentiment of the messages and the sender category, the abusive messages may be sent to an administrator for review and to take appropriate action. As a result, such messages may be blocked from the intended recipient device. The system may analyse the sentiment of the messages using a machine learning approach, for instance employing a Naive Bayes algorithm. An inference model may be generated via the machine learning. The inference model may produce a metric that is used when evaluating the message sentiment.",cyberbullying may mitigated intercepting accurately analyzing sentiment social medium message presenting intended recipient device based sentiment message sender category abusive message may sent administrator review take appropriate action result message may blocked intended recipient device system may analyse sentiment message using machine learning approach instance employing naive bayes algorithm inference model may generated via machine learning inference model may produce metric used evaluating message sentiment,0
"A machine learning-based system and method for content clustering and content threat assessment includes generating embedding values for each piece of content of corpora of content data; implementing unsupervised machine learning models that: receive model input comprising the embeddings values of each piece of content of the corpora of content data; and predict distinct clusters of content data based on the embeddings values of the corpora of content data; assessing the distinct clusters of content data; associating metadata with each piece of content defining a member in each of the distinct clusters of content data based on the assessment, wherein the associating the metadata includes attributing to each piece of content within the clusters of content data a classification label of one of digital abuse/digital fraud and not digital abuse/digital fraud; and identifying members or content clusters having digital fraud/digital abuse based on querying the distinct clusters of content data.",machine learningbased system method content clustering content threat assessment includes generating embedding value piece content corpus content data implementing unsupervised machine learning model receive model input comprising embeddings value piece content corpus content data predict distinct cluster content data based embeddings value corpus content data assessing distinct cluster content data associating metadata piece content defining member distinct cluster content data based assessment wherein associating metadata includes attributing piece content within cluster content data classification label one digital abusedigital fraud digital abusedigital fraud identifying member content cluster digital frauddigital abuse based querying distinct cluster content data,2
"A system and method for automated anomaly detection in automated disposal decisions of an automated decisioning workflow includes collecting a time-series of automated disposal decision data for a current period from an automated decisioning workflow, wherein the automated decisioning workflow computes one of a plurality of distinct disposal decisions for each distinct input comprising subject online event data and a machine learning-based threat score computed for the subject online event data; selecting an anomaly detection algorithm from a plurality of distinct anomaly detection algorithms based on a type of online abuse or online fraud that the automated decisioning workflow is configured to evaluate; evaluating, using the selected anomaly detection algorithm, the time-series of automated decision data for the current period; computing whether anomalies exist in the time-series of automated disposal decision data for the current period based on the evaluation; and generating an anomaly alert based on the computation.",system method automated anomaly detection automated disposal decision automated decisioning workflow includes collecting timeseries automated disposal decision data current period automated decisioning workflow wherein automated decisioning workflow computes one plurality distinct disposal decision distinct input comprising subject online event data machine learningbased threat score computed subject online event data selecting anomaly detection algorithm plurality distinct anomaly detection algorithm based type online abuse online fraud automated decisioning workflow configured evaluate evaluating using selected anomaly detection algorithm timeseries automated decision data current period computing whether anomaly exist timeseries automated disposal decision data current period based evaluation generating anomaly alert based computation,2
A method for preventing cyberbullying on a social media messaging platform by limiting comments to user submitted content posts to only two-user conversation exchanges between the author of the content post and the person initiating the conversation exchange. The two users in the conversation exchange are able to submit replies only when it is their turn such that both participants may terminate the conversation exchange by failing to reply to the immediately preceding post by the other user.,method preventing cyberbullying social medium messaging platform limiting comment user submitted content post twouser conversation exchange author content post person initiating conversation exchange two user conversation exchange able submit reply turn participant may terminate conversation exchange failing reply immediately preceding post user,0
"To provide a harassment detection program, a harassment detection system, and a harassment detection method for appropriately detecting occurrence of harassment.SOLUTION: A harassment detection program acquires collation information for collating voice data on a first person with the positions of the first person and a second person, that is, collation information related to the first person, and acquires physical information data and collation information on the second person, and detects first suspicions related to harassment of the first person on the basis of the voice data on the first person, and detects second suspicions related to harassment of the second person on the basis of the physical information data acquired in relation to the second person, and detects occurrence of harassment between the first person and the second person on the basis of a collation result between a detection period of the first suspicions and a detection period of the second suspicions and the collation information acquired in relation to the first person and the collation information acquired in relation to the second person.SELECTED DRAWING: Figure 13",provide harassment detection program harassment detection system harassment detection method appropriately detecting occurrence harassmentsolution harassment detection program acquires collation information collating voice data first person position first person second person collation information related first person acquires physical information data collation information second person detects first suspicion related harassment first person basis voice data first person detects second suspicion related harassment second person basis physical information data acquired relation second person detects occurrence harassment first person second person basis collation result detection period first suspicion detection period second suspicion collation information acquired relation first person collation information acquired relation second personselected drawing figure,-1
"Systems and methods include: implementing a first machine learning model to generate an output of a global digital threat score for an online activity based on an input of the collected digital event data; implementing a second machine learning model that generates a category inference of a category of digital fraud or a category of digital abuse from a plurality of digital fraud or digital abuse categories; selecting a third machine learning model from an ensemble of digital fraud or digital abuse machine learning models based on the category inference generated by the second machine learning model, wherein the ensemble of digital fraud or digital abuse machine learning models comprise a plurality of disparate digital fraud or digital abuse category-specific machine learning models; and implementing the selected third machine learning model to generate a digital fraud or digital abuse category-specific threat score based on the digital event data.",system method include implementing first machine learning model generate output global digital threat score online activity based input collected digital event data implementing second machine learning model generates category inference category digital fraud category digital abuse plurality digital fraud digital abuse category selecting third machine learning model ensemble digital fraud digital abuse machine learning model based category inference generated second machine learning model wherein ensemble digital fraud digital abuse machine learning model comprise plurality disparate digital fraud digital abuse categoryspecific machine learning model implementing selected third machine learning model generate digital fraud digital abuse categoryspecific threat score based digital event data,2
"A water-in-fuel abuse detection system provides a way to determine if a vehicle operator has ignored a conventional water-in-fuel indicator light and continued to operate the vehicle beyond a certain threshold. The system includes a sensor positioned in a fuel filter capable of separating an amount of water from a source of fuel. The sensor is operatively connected to a software routine, as well as to a conventional indicator light that illuminates to alert a vehicle operator that water must be purged from the fuel filtration system. The software routine determines the duration, in distance traversed or time elapsed, that the amount of water is at or above the level of the sensor. The routine then writes a fault code to permanent memory when the threshold is exceeded. A diagnostic tool can access the permanent memory and reveal whether the fuel system has be the subject of water-in-fuel abuse.",waterinfuel abuse detection system provides way determine vehicle operator ignored conventional waterinfuel indicator light continued operate vehicle beyond certain threshold system includes sensor positioned fuel filter capable separating amount water source fuel sensor operatively connected software routine well conventional indicator light illuminates alert vehicle operator water must purged fuel filtration system software routine determines duration distance traversed time elapsed amount water level sensor routine writes fault code permanent memory threshold exceeded diagnostic tool access permanent memory reveal whether fuel system subject waterinfuel abuse,1
"The present invention generally relates to a system for predicting hate speech on social networking platforms comprises a pre-processing module for pre-processing text speech collected from social media sites for removing unwanted information from the speech; a decision-making module for extracting features using adaptive polynomial lexicon partial least square method thereafter negation lexicon creation and correlation analysis using gold elephant herd optimization approach (GEHO); and a decision classification module for classifying the speech into hate speech and non-harmful speech depending upon ranking generated by a discrete feed forward perceptron neural network. fa a, I-",present invention generally relates system predicting hate speech social networking platform comprises preprocessing module preprocessing text speech collected social medium site removing unwanted information speech decisionmaking module extracting feature using adaptive polynomial lexicon partial least square method thereafter negation lexicon creation correlation analysis using gold elephant herd optimization approach geho decision classification module classifying speech hate speech nonharmful speech depending upon ranking generated discrete feed forward perceptron neural network,0
"In some cases, lower quality, large scale training data can be automatically generated by automatic labeling. The generated training data can be used to pre-train a machine learning model. For instance, the model can be a model for detection of verbal harassment. Parameters of the pre-trained model can be refined or updated using another one or more higher-quality sets of training data, with which the model can be subsequently trained.",case lower quality large scale training data automatically generated automatic labeling generated training data used pretrain machine learning model instance model model detection verbal harassment parameter pretrained model refined updated using another one higherquality set training data model subsequently trained,0
"Example implementations described herein are directed to systems, methods, and computer programs for the management of live or streaming broadcasts for policy violations, which can include buffering a live stream broadcast, processing the buffered live stream broadcast with one or more processors configured with a machine learning algorithm for detecting a policy violation, and for the processing indicative of the policy violation existing in the buffered live stream broadcast, causing the buffered live stream broadcast to be modified. Such policy violations can include nudity, hate speech, copyright infringement, age inappropriate content and other violations in accordance with the desired implementation.",example implementation described herein directed system method computer program management live streaming broadcast policy violation include buffering live stream broadcast processing buffered live stream broadcast one processor configured machine learning algorithm detecting policy violation processing indicative policy violation existing buffered live stream broadcast causing buffered live stream broadcast modified policy violation include nudity hate speech copyright infringement age inappropriate content violation accordance desired implementation,0
"A method of an electronic device for abuse detection and notification is disclosed herewith. The method includes monitoring one or more parameters at the electronic device for one or more physical events, the parameter(s) being associated with one or more imagers. The method further includes identifying the physical event(s) at the electronic device by determining that each parameter exceeds a corresponding threshold value. Next, the method provides storing event data corresponding to the physical event(s), in which at least a portion of the event data is associated with the parameter(s). The method further includes generating a notification associated with the physical event(s).",method electronic device abuse detection notification disclosed herewith method includes monitoring one parameter electronic device one physical event parameter associated one imagers method includes identifying physical event electronic device determining parameter exceeds corresponding threshold value next method provides storing event data corresponding physical event least portion event data associated parameter method includes generating notification associated physical event,1
"A method, computer program product, and computing system for: receiving a request from a user to use grounding material in a generative AI system; establishing a network connection with trusted-source material to allow access to the trusted-source material; processing the grounding material to confirm the integrity of the grounding material; and allowing the grounding material to be utilized in the generative AI system if the integrity of the grounding material is confirmed.",method computer program product computing system receiving request user use grounding material generative system establishing network connection trustedsource material allow access trustedsource material processing grounding material confirm integrity grounding material allowing grounding material utilized generative system integrity grounding material confirmed,-1
A computing system includes two separate computer modules within the same computing housing. The computing system protects data from one computer from online threats by permanently keeping the computer offline and disconnected from networks or the Internet. Sensitive or important data may thus be worked on without fear of exposure to online threats that may sneak into the data storage using subterfuge or undetected entry. The user may switch to the other computer which has network connectivity to access network data or the Internet while the data in the offline computer is safely disconnected and protected from access by the other computer's connectivity.,computing system includes two separate computer module within computing housing computing system protects data one computer online threat permanently keeping computer offline disconnected network internet sensitive important data may thus worked without fear exposure online threat may sneak data storage using subterfuge undetected entry user may switch computer network connectivity access network data internet data offline computer safely disconnected protected access computer connectivity,2
"The safe pixel is code embedded in a web page that is executed when the web page is accessed by a user agent. When the safe pixel is executed, the safe pixel collects information about the device and invokes the execution of one or more abuse detection functions. Each abuse detection function implements a different technique for estimating the likelihood of abusive behavior being the cause of the safe pixel being executed. The safe pixel transmits in a reporting message the local information and the results of the abuse detection function executions to a traffic server. The traffic server analyzes the reporting message to make a determination of the validity of the action that caused the safe pixel being executed.",safe pixel code embedded web page executed web page accessed user agent safe pixel executed safe pixel collect information device invokes execution one abuse detection function abuse detection function implement different technique estimating likelihood abusive behavior cause safe pixel executed safe pixel transmits reporting message local information result abuse detection function execution traffic server traffic server analyzes reporting message make determination validity action caused safe pixel executed,-1
"A fraud and abuse detection method includes analyzing an incoming call in near real-time using a sentiment analysis module, where the sentiment analysis module includes one or more sentiment analysis models configured to analyze a sentiment of a callee's voice. The method includes generating a confidence risk score in near real-time based on the sentiment analysis of the incoming call, where the confidence risk score corresponds to a likelihood of fraud or abuse based on the sentimental analysis data from the sentiment analysis module. The method includes performing one or more actions using a circuit breaker module based on a determined risk score, where the one or more actions include one or more risk threshold tier actions corresponding to a respective confidence risk score.",fraud abuse detection method includes analyzing incoming call near realtime using sentiment analysis module sentiment analysis module includes one sentiment analysis model configured analyze sentiment callees voice method includes generating confidence risk score near realtime based sentiment analysis incoming call confidence risk score corresponds likelihood fraud abuse based sentimental analysis data sentiment analysis module method includes performing one action using circuit breaker module based determined risk score one action include one risk threshold tier action corresponding respective confidence risk score,1
To provide a technique for accurately detecting an electronic mail including a harassment word and contributing to construction of an environment having no harassment.SOLUTION: A harassment detection device includes: a reception section 11b for acquiring an electronic mail transmitted from a terminal device of a user; an analysis section 11c for performing morphological analysis of the electronic mail to extract a keyword; a storage section 13 for storing a harassment word; a registration section 11e for associating presence/absence of identification with the harassment word in the storage section when a terminal device of an administrator identifies the harassment word; a determination section 11d for comparing the keyword with the identified harassment word and determining whether or not the identified harassment word is contained in the keyword; and a warning section 11f for issuing a predetermined warning to the terminal device of the user when it is determined that the identified harassment word is contained in the keyword.SELECTED DRAWING: Figure 2,provide technique accurately detecting electronic mail including harassment word contributing construction environment harassmentsolution harassment detection device includes reception section acquiring electronic mail transmitted terminal device user analysis section performing morphological analysis electronic mail extract keyword storage section storing harassment word registration section associating presenceabsence identification harassment word storage section terminal device administrator identifies harassment word determination section comparing keyword identified harassment word determining whether identified harassment word contained keyword warning section issuing predetermined warning terminal device user determined identified harassment word contained keywordselected drawing figure,-1
"Systems and methods for detecting digital abuse or digital fraud that involves malicious account testing includes implementing a machine learning threat model that predicts malicious account testing using misappropriate accounts, wherein a subset of a plurality of learnable variables of an algorithmic structure of the machine learning threat model includes one or more learnable variables derived based on feature data indicative of malicious account testing; wherein implementing the machine learning threat model includes: (i) identifying event data from an online event that is suspected to involve digital fraud or digital abuse, (ii) extracting adverse feature data from the event data that map to the one or more learnable variables of the subset, and (iii) providing the adverse feature data as model input to the machine learning threat model; and computing, using the machine learning threat model, a threat prediction indicating a probability that the online event involves malicious account testing.",system method detecting digital abuse digital fraud involves malicious account testing includes implementing machine learning threat model predicts malicious account testing using misappropriate account wherein subset plurality learnable variable algorithmic structure machine learning threat model includes one learnable variable derived based feature data indicative malicious account testing wherein implementing machine learning threat model includes identifying event data online event suspected involve digital fraud digital abuse extracting adverse feature data event data map one learnable variable subset iii providing adverse feature data model input machine learning threat model computing using machine learning threat model threat prediction indicating probability online event involves malicious account testing,2
"The invention relates to a method for protecting a user of one or more social networks (30) or video games, using a connected device (7), against risks of cyberbullying, comprising carrying out semantic and contextual analysis on accessed or received digital content, employing artificial-intelligence techniques implementing a plurality of brains (C1-C5) each dedicated to a particular cyberbullying theme and operating simultaneously, and carrying out processing of the results of the semantic and contextual analysis in order to detect a cyberbullying situation or a toxicity of all or part of said content. If a cyberbullying situation or a toxicity of digital content is detected, the protection method according to the invention writes (105), to a blockchain (15) on the Web3, a set of data describing this cyberbullying, and masks (104) the display of the toxic digital content on the screen of the connected device (7).",invention relates method protecting user one social network video game using connected device risk cyberbullying comprising carrying semantic contextual analysis accessed received digital content employing artificialintelligence technique implementing plurality brain dedicated particular cyberbullying theme operating simultaneously carrying processing result semantic contextual analysis order detect cyberbullying situation toxicity part said content cyberbullying situation toxicity digital content detected protection method according invention writes blockchain web set data describing cyberbullying mask display toxic digital content screen connected device,0
"Systems and methods for identifying flagged content. One computer-based system includes an electronic processor configured to receive one or more websites, each website including a label identifying a flagged category and content, analyze one or more words included in the content of each of the one or more websites, and associate at least one of the one or more words included in the content of each of the one or more websites with the flagged category. The electronic processor is configured to perform, using the at least one of the one or more words, a query within a search engine to obtain one or more second websites, label each of the one or more second websites with the label identifying the flagged category, and update a model with the one or more websites, the one or more second websites, the one or more words, and the associated labels.",system method identifying flagged content one computerbased system includes electronic processor configured receive one website website including label identifying flagged category content analyze one word included content one website associate least one one word included content one website flagged category electronic processor configured perform using least one one word query within search engine obtain one second website label one second website label identifying flagged category update model one website one second website one word associated label,-1
"The present invention relates to detection of contentious content for online media. Specifically, the present invention relates to the detection of contentious content such as hate speech. According to the first aspect, there is provided a method for training a machine learning classifier to detect contentious content, the method comprising the steps of: receiving content data 102 as input data; receiving annotation data 104 for said content; receiving metadata 106 in relation to said annotation data; and determining a learned approach to classifying whether the content is contentious based on said annotation data for said content and said metadata in relation to said annotation data. The method may receive further content as input data; determine a classification whether the further content is contentious using the classifier and further determining the learned approach to a high degree of certainty. The content may be generated online. The method may comprise reviewing the source of the content, reviewing the relationship between the source of the content and the user, reviewing the domain from which the content was generated, reviewing the profile and user history of the author of the content and/or performing natural language processing.",present invention relates detection contentious content online medium specifically present invention relates detection contentious content hate speech according first aspect provided method training machine learning classifier detect contentious content method comprising step receiving content data input data receiving annotation data said content receiving metadata relation said annotation data determining learned approach classifying whether content contentious based said annotation data said content said metadata relation said annotation data method may receive content input data determine classification whether content contentious using classifier determining learned approach high degree certainty content may generated online method may comprise reviewing source content reviewing relationship source content user reviewing domain content generated reviewing profile user history author content andor performing natural language processing,0
"A method of providing internet security is provided that includes accessing and monitoring a list of online threat exchanges or indexes, wherein accessing the list occurs in real-time and is continuously updated, storing the monitored information at a server, monitoring at least one honeypot established by an operator of the server, wherein monitoring the honeypot occurs in real-time and is continuously updated, compiling a database based on the accessed list and monitored honeypot, and implementing a security measure based on the compiled database.",method providing internet security provided includes accessing monitoring list online threat exchange index wherein accessing list occurs realtime continuously updated storing monitored information server monitoring least one honeypot established operator server wherein monitoring honeypot occurs realtime continuously updated compiling database based accessed list monitored honeypot implementing security measure based compiled database,2
"A method for machine learning-based detection of an automated fraud or abuse attack includes: identifying, via a computer network, a digital event associated with a suspected automated fraud or abuse attack; composing, via one or more computers, a digital activity signature of the suspected automated fraud or abuse attack based on digital activity associated with the suspected automated fraud or abuse attack; computing, via a machine learning model, an encoded representation of the digital activity signature; searching, via the one or more computers, an automated fraud or abuse signature registry based on the encoded representation of the digital activity signature; determining a likely origin of the digital event based on the searching of the automated fraud or abuse signature registry; and selectively implementing one or more automated threat mitigation actions based on the likely origin of the digital event.",method machine learningbased detection automated fraud abuse attack includes identifying via computer network digital event associated suspected automated fraud abuse attack composing via one computer digital activity signature suspected automated fraud abuse attack based digital activity associated suspected automated fraud abuse attack computing via machine learning model encoded representation digital activity signature searching via one computer automated fraud abuse signature registry based encoded representation digital activity signature determining likely origin digital event based searching automated fraud abuse signature registry selectively implementing one automated threat mitigation action based likely origin digital event,2
"The present invention is directed at a system, method and device for detecting offensive content on a portable electronic device, by monitoring communications sent, received or stored on the portable electronic device, and wherein monitoring comprises collecting content data, classifying content data by calculating an alert score for content data wherein an alert score corresponds to offensive content detected, and sending an alert notification to a second portable electronic device to alert the detection of offensive content on the first portable electronic device.",present invention directed system method device detecting offensive content portable electronic device monitoring communication sent received stored portable electronic device wherein monitoring comprises collecting content data classifying content data calculating alert score content data wherein alert score corresponds offensive content detected sending alert notification second portable electronic device alert detection offensive content first portable electronic device,1
"In one aspect, a computerized method for detecting data abuse and data exfiltration in a data store or a data lakes cloud warehouse, comprising: identifying a plurality of Command and control (CnC) channels in an enterprise data cloud infrastructure; identifying and detecting malicious compressed data transfers and encrypted data transfers; implementing a destination analysis from within the data store; and implementing data abuse detection and prevention operations.",one aspect computerized method detecting data abuse data exfiltration data store data lake cloud warehouse comprising identifying plurality command control cnc channel enterprise data cloud infrastructure identifying detecting malicious compressed data transfer encrypted data transfer implementing destination analysis within data store implementing data abuse detection prevention operation,-1
To appropriately detect a potential abuse of an abuse subject.SOLUTION: An abuse detection device 40 includes: an acquisition unit 41 that acquires growth characteristic information 411 indicating a characteristic related to growth of a subject and action characteristic information 412 indicating a characteristic related to an action of the subject; a determination unit 42 that determines that there is a possibility that an abuse of the subject is present when the growth characteristic information 411 and the action characteristic information 412 meet a criterion 420 for determining whether or not there is a possibility that the abuse is present; and an output unit 43 that outputs a determination result 430 by the determination unit 42.SELECTED DRAWING: Figure 3,appropriately detect potential abuse abuse subjectsolution abuse detection device includes acquisition unit acquires growth characteristic information indicating characteristic related growth subject action characteristic information indicating characteristic related action subject determination unit determines possibility abuse subject present growth characteristic information action characteristic information meet criterion determining whether possibility abuse present output unit output determination result determination unit selected drawing figure,1
"A telephony communications system for detecting abuse in a public telephone network to which a telephone network subscriber is connected includes: a telephone system server, configured to: emulate an extension subscriber in order to simulate the existence of the emulated extension subscriber of the telephone system vis--vis an attacking entity, receive a control command from the attacking entity to establish a telephone connection between the emulated extension subscriber and the telephone network subscriber, and send a connection request to the telephone network subscriber in response to receiving the control command in order to initiate the establishment of the telephone connection between the emulated extension subscriber and the telephone network subscriber; and a telephone network abuse detection device configured to detect an abuse attempt in the public telephone network on the basis of the telephone network address of the telephone network subscriber.",telephony communication system detecting abuse public telephone network telephone network subscriber connected includes telephone system server configured emulate extension subscriber order simulate existence emulated extension subscriber telephone system visvis attacking entity receive control command attacking entity establish telephone connection emulated extension subscriber telephone network subscriber send connection request telephone network subscriber response receiving control command order initiate establishment telephone connection emulated extension subscriber telephone network subscriber telephone network abuse detection device configured detect abuse attempt public telephone network basis telephone network address telephone network subscriber,1
"A system and method for adapting an errant automated decisioning workflow includes reconfiguring digital abuse or digital fraud logic parameters associated with automated decisioning routes of an automated decisioning workflow in response to identifying an anomalous drift or an anomalous shift in efficacy metrics of the automated decisioning workflow, wherein the automated decisioning workflow includes a plurality of distinct automated decisioning routes that, when applied in a digital threat evaluation of data associated with a target digital event, automatically compute a decision for disposing the target digital event based on a probability digital fraud; simulating, by computers, a performance of the automated decisioning routes in a reconfigured state based on inputs of historical digital event data; calculating simulation metrics based on simulation output data of the simulation; and promoting to an in-production state the automated decisioning workflow having the automated decisioning routes in the reconfigured state.",system method adapting errant automated decisioning workflow includes reconfiguring digital abuse digital fraud logic parameter associated automated decisioning route automated decisioning workflow response identifying anomalous drift anomalous shift efficacy metric automated decisioning workflow wherein automated decisioning workflow includes plurality distinct automated decisioning route applied digital threat evaluation data associated target digital event automatically compute decision disposing target digital event based probability digital fraud simulating computer performance automated decisioning route reconfigured state based input historical digital event data calculating simulation metric based simulation output data simulation promoting inproduction state automated decisioning workflow automated decisioning route reconfigured state,2
"Disclosed are a method for correcting psychological damage based on cyberbullying and Internet addiction using smart device linkage, and an apparatus for the same. The method for correcting psychological damage according to an embodiment of the present invention comprises the following steps: monitoring the use of a first smart device which is used by a user; monitoring the use of a second smart device which is interlocked with the first smart device and is capable of measuring biometric data of the user; generating a diagnosis result on whether or not the user has suffered from cyberbullying and is addicted to the Internet based on monitoring results; and generating correction feedback for an item to be corrected determined based on the diagnosis result, and providing the correction feedback through the first smart device or the second smart device. An objective of the present invention is to accurately diagnose a psychological state of a user caused by cyberbullying and whether or not the user is addicted to the Internet through Internet usage monitoring using interlocked smart devices, and to correct the user's psychological damage based on diagnosed results.",disclosed method correcting psychological damage based cyberbullying internet addiction using smart device linkage apparatus method correcting psychological damage according embodiment present invention comprises following step monitoring use first smart device used user monitoring use second smart device interlocked first smart device capable measuring biometric data user generating diagnosis result whether user suffered cyberbullying addicted internet based monitoring result generating correction feedback item corrected determined based diagnosis result providing correction feedback first smart device second smart device objective present invention accurately diagnose psychological state user caused cyberbullying whether user addicted internet internet usage monitoring using interlocked smart device correct user psychological damage based diagnosed result,-1
"The invention discloses a permission abuse detection method and device, electronic equipment and a readable storage medium, and relates to the technical field of neural networks, and the method comprises the steps: obtaining operation behavior data corresponding to an operation behavior of a user on the electronic equipment; acquiring system state information of the electronic equipment; obtaining access information corresponding to the access operation of the target application program on the private data; based on the operation behavior data, the system state information and the access information, determining a permission abuse detection result of the target application program through a pre-trained permission abuse detection model; and outputting a malicious access prompt under the condition of determining that the target application program has malicious access based on the permission abuse detection result. According to the application, the problems of user information leakage and poor user experience caused by malicious access of the target application program to the privacy data of the user are avoided.",invention discloses permission abuse detection method device electronic equipment readable storage medium relates technical field neural network method comprises step obtaining operation behavior data corresponding operation behavior user electronic equipment acquiring system state information electronic equipment obtaining access information corresponding access operation target application program private data based operation behavior data system state information access information determining permission abuse detection result target application program pretrained permission abuse detection model outputting malicious access prompt condition determining target application program malicious access based permission abuse detection result according application problem user information leakage poor user experience caused malicious access target application program privacy data user avoided,1
"The invention relates to a method for protecting a user of one or more social networks (3) or video games (4) from the risks of cyberbullying, wherein this user has a device (6-10) connected to a communication network (2) for accessing digital content originating from the one or more social networks (3) or video games (4), or for receiving digital content originating from one or more other users of the one or more social networks (3) or video games (4), and wherein the method comprises steps of performing a semantic and contextual analysis, of processing the results of the semantic and contextual analysis in order to detect a situation of cyberbullying or toxicity, and, in the event of detection of a situation of cyberbullying or toxicity in digital content, displaying the toxic digital content thus detected on the screen of the connected device. This method further comprises, upstream of the semantic and contextual analysis step, a step of collecting (data mining) digital content from a data stream received from a social network, and a step of recording, in a blockchain, a set of descriptive data describing this cyberbullying or toxicity.",invention relates method protecting user one social network video game risk cyberbullying wherein user device connected communication network accessing digital content originating one social network video game receiving digital content originating one user one social network video game wherein method comprises step performing semantic contextual analysis processing result semantic contextual analysis order detect situation cyberbullying toxicity event detection situation cyberbullying toxicity digital content displaying toxic digital content thus detected screen connected device method comprises upstream semantic contextual analysis step step collecting data mining digital content data stream received social network step recording blockchain set descriptive data describing cyberbullying toxicity,0
"Neural network systems are provided that comprise one or more neural networks. The first neural network can comprise a convolutional neural network (CNN) long short-term memory (LSTM) architecture for receiving a primary data set comprising text messages and output a primary data structure comprising a text pattern-based feature. The second neural network can comprise a CNN architecture for receiving a secondary data sets derived from the primary data set and output a plurality of secondary data structures. The third neural network can combine the data structures to produce a combined data structure, and then process it to produce a categorized data structure comprising the text messages assigned to targets. The primary data set can comprise hate speech and the categorized data structure can comprise target categories, for example, hate targets. Methods of operating neural network systems and computer program products for performing such methods are also provided.",neural network system provided comprise one neural network first neural network comprise convolutional neural network cnn long shortterm memory lstm architecture receiving primary data set comprising text message output primary data structure comprising text patternbased feature second neural network comprise cnn architecture receiving secondary data set derived primary data set output plurality secondary data structure third neural network combine data structure produce combined data structure process produce categorized data structure comprising text message assigned target primary data set comprise hate speech categorized data structure comprise target category example hate target method operating neural network system computer program product performing method also provided,0
"Systems and methods for access key abuse detection, the systems and methods including steps of receiving activity data relating to an access key from cloud providers associated with a cloud-based system, generating a baseline for the access key based on the activity data, monitoring activities associated with the access key in the cloud-based system, and calculating a score for monitored activities based on a comparison of the monitored activities to the baseline. The present scoring system helps identify an abnormal and risky activity that indicates an attacker is abusing the access key. In addition, a baseline is created for a plurality of selected attributes that present the normal access key usage in order to identify malicious abnormal activities.",system method access key abuse detection system method including step receiving activity data relating access key cloud provider associated cloudbased system generating baseline access key based activity data monitoring activity associated access key cloudbased system calculating score monitored activity based comparison monitored activity baseline present scoring system help identify abnormal risky activity indicates attacker abusing access key addition baseline created plurality selected attribute present normal access key usage order identify malicious abnormal activity,1
A server system is provided that includes one or more processors configured to execute a platform for an online multi-user chat service that communicates with a plurality of client devices of users of the online multi-user chat service that exchanges user chat data between the plurality of client devices. The one or more processors are configured to execute a user chat filtering program that performs filter actions for user chat data exchanged on the platform for the online multi-user chat service. The user chat filtering program includes a plurality of trained machine learning models and a filter decision service that determines a filter action to be performed for target portions of user chat data based on output of the plurality of trained machine learning models for those target portions of user chat data.,server system provided includes one processor configured execute platform online multiuser chat service communicates plurality client device user online multiuser chat service exchange user chat data plurality client device one processor configured execute user chat filtering program performs filter action user chat data exchanged platform online multiuser chat service user chat filtering program includes plurality trained machine learning model filter decision service determines filter action performed target portion user chat data based output plurality trained machine learning model target portion user chat data,-1
"A computer-implemented method for detecting market abuse in a data processing system, the method comprising: collecting a plurality of first events associated with a first stock trade occurring within a predetermined period of time; grouping the plurality of first events into different event groups, each group having a different type of first events; encoding each first event as one or more characters, and encoding each type of first events as a first string; collecting all the first strings in a sequence corresponding to different types of first events; feeding the sequence of first strings into a trained machine learning model; and determining, by the trained machine learning model, whether there is market abuse in the first stock trade.",computerimplemented method detecting market abuse data processing system method comprising collecting plurality first event associated first stock trade occurring within predetermined period time grouping plurality first event different event group group different type first event encoding first event one character encoding type first event first string collecting first string sequence corresponding different type first event feeding sequence first string trained machine learning model determining trained machine learning model whether market abuse first stock trade,2
"A system 100 and method to detect online threats and protect online assets. A user module 202 registers user(s) and stores user identity details of one or more social media platforms associated with the users. A monitoring module 204 monitors electronic communications corresponding to the social media platforms associated with registered users. An artificial intelligence module 206 learns user preferences and behaviours of the registered users associated with the social media platforms and creates customized security measures for the registered users. Preferably, the artificial intelligence module detects anomalous behaviours and generates a customised security action plan based on the detected anomalies. A notification module 208 analyses the social media platforms of the registered users to identity potential security threats and generate alert notifications to the corresponding registered users on the identified potential security threats. An action module 210 enables the registered users to initiate action against identified potential security threats.",system method detect online threat protect online asset user module register user store user identity detail one social medium platform associated user monitoring module monitor electronic communication corresponding social medium platform associated registered user artificial intelligence module learns user preference behaviour registered user associated social medium platform creates customized security measure registered user preferably artificial intelligence module detects anomalous behaviour generates customised security action plan based detected anomaly notification module analysis social medium platform registered user identity potential security threat generate alert notification corresponding registered user identified potential security threat action module enables registered user initiate action identified potential security threat,2
"An audio comment feature is added to livestream chat. A viewer of the livestream can record (402) a voice clip and post (800) that audio comment to the chat. A screening system ingests the audio clip, converting it (802) to text using a speech-to-text algorithm. The text version of the audio clip is processed (904) by an AI moderation algorithm to filter out (908) objectionable content. Clips that pass through the filter are displayed (906) to the livestreamer as a text comment with an option to play the audio live on the air. The livestreamer can watch this feed of text comments during the stream. Upon identifying a comment worth broadcasting on the stream, the streamer can click a Play button on the text version of the comment to play (504) the audio version of the comment live on the stream.",audio comment feature added livestream chat viewer livestream record voice clip post audio comment chat screening system ingests audio clip converting text using speechtotext algorithm text version audio clip processed moderation algorithm filter objectionable content clip pas filter displayed livestreamer text comment option play audio live air livestreamer watch feed text comment stream upon identifying comment worth broadcasting stream streamer click play button text version comment play audio version comment live stream,0
"Endorsement abuse detection via social interactions is described, including generating an endorsement log comprising an endorser identifier, a target identifier, endorsement data, and a token indicative of an endorsement event; analyzing the endorsement log with respect to a user aggregator and a target aggregator, to generate an online endorsement abuse candidate; generating an endorsement overlap graph for the online endorsement abuse candidate based on the endorsement log, the user aggregator and the target aggregator, wherein nodes of the endorsement overlap graph represent ones of the online endorsement abuse candidate, and edges represent a number of shared endorsements; and determining whether the endorsement event is authorized based an analysis of the endorsement overlap graph and an orthogonal signal at least one of transmitted and received by the ones of the online endorsement abuse candidate.",endorsement abuse detection via social interaction described including generating endorsement log comprising endorser identifier target identifier endorsement data token indicative endorsement event analyzing endorsement log respect user aggregator target aggregator generate online endorsement abuse candidate generating endorsement overlap graph online endorsement abuse candidate based endorsement log user aggregator target aggregator wherein node endorsement overlap graph represent one online endorsement abuse candidate edge represent number shared endorsement determining whether endorsement event authorized based analysis endorsement overlap graph orthogonal signal least one transmitted received one online endorsement abuse candidate,1
"Disclosed in the present application are a clustering analysis-based domain name abuse detection method and system. The method comprises: selecting multi-dimensional features of a domain name application; establishing an one-dimensional feature coordinate system corresponding to each feature amongst the multi-dimensional features, the one-dimensional feature coordinate system being used for identifying the position in the coordinate system of a numerical value of the feature converted according to a preset numerical standard; according to all of the one-dimensional feature coordinate systems, establishing a multi-dimensional feature coordinate system; according to a domain name list or a URL list, acquiring a preset number of domain name applications; collecting multi-dimensional features of the domain name applications; according to the preset numerical standard, converting each feature amongst the domain name multi-dimensional features into a numerical value identified in the multi-dimensional feature coordinate system; and calculating the aggregation condition of the domain name applications according to the numerical values identified in the multi-dimensional feature coordinate system, and obtaining a domain name abuse detection result according to the aggregation condition. Therefore, the purposes of not depending on a single feature, high detection efficiency and high accuracy are achieved.",disclosed present application clustering analysisbased domain name abuse detection method system method comprises selecting multidimensional feature domain name application establishing onedimensional feature coordinate system corresponding feature amongst multidimensional feature onedimensional feature coordinate system used identifying position coordinate system numerical value feature converted according preset numerical standard according onedimensional feature coordinate system establishing multidimensional feature coordinate system according domain name list url list acquiring preset number domain name application collecting multidimensional feature domain name application according preset numerical standard converting feature amongst domain name multidimensional feature numerical value identified multidimensional feature coordinate system calculating aggregation condition domain name application according numerical value identified multidimensional feature coordinate system obtaining domain name abuse detection result according aggregation condition therefore purpose depending single feature high detection efficiency high accuracy achieved,1
Fraud and abuse detection in an entity's payment coding practices includes the ability to search for fraud at all levels of the hierarchical coded payment system within the context of an unsupervised model. The model uses variables derived and profiles created at any level or at all levels of the hierarchical coded payment system to create a comprehensive description of the payment coding activities submitted by the entity. That description is compared with other peer entities to determine unusual and To potentially inappropriate activity. The profiles created may themselves be utilized for purposes other than the detection of fraud and abuse.,fraud abuse detection entity payment coding practice includes ability search fraud level hierarchical coded payment system within context unsupervised model model us variable derived profile created level level hierarchical coded payment system create comprehensive description payment coding activity submitted entity description compared peer entity determine unusual potentially inappropriate activity profile created may utilized purpose detection fraud abuse,-1
Fraud and abuse detection in an entity's payment coding practices includes the ability to search for fraud at all levels of the hierarchical coded payment system within the context of an unsupervised model. The model uses variables derived and profiles created at any level or at all levels of the hierarchical coded payment system to create a comprehensive description of the payment coding activities submitted by the entity. That description is compared with other peer entities to determine unusual and potentially inappropriate activity. The profiles created may themselves be utilized for purposes other than the detection of fraud and abuse.,fraud abuse detection entity payment coding practice includes ability search fraud level hierarchical coded payment system within context unsupervised model model us variable derived profile created level level hierarchical coded payment system create comprehensive description payment coding activity submitted entity description compared peer entity determine unusual potentially inappropriate activity profile created may utilized purpose detection fraud abuse,-1
A method for online voice content moderation provides a multi-stage voice content analysis system. The system includes a pre-moderator stage having a toxicity scorer configured to provide a toxicity score for a given toxic speech content from a user. The toxicity score is a function of a platform content policy. The method generates a toxicity score for the given toxic speech content. The toxic speech content is provided to a moderator as a function of the toxicity score.,method online voice content moderation provides multistage voice content analysis system system includes premoderator stage toxicity scorer configured provide toxicity score given toxic speech content user toxicity score function platform content policy method generates toxicity score given toxic speech content toxic speech content provided moderator function toxicity score,-1
"A client computer may be configured to perform computer security operation services, such as malicious code scanning and protection against online threats, using one of several remotely located server computers. The client computer may be configured to determine an operational state of the server computers and determine a protection status of the client computer resulting from use of a server computer of a particular operational state. The protection status may have one of at least three levels and indicate vulnerability of the client computer. The client computer may determine the operational state of a server computer based on available bandwidth for network communication between the client computer and the server computer. The client computer may be configured to allow for automatic or manual selection of another server computer when the currently selected server computer results in the client computer having a protection status below a threshold level.",client computer may configured perform computer security operation service malicious code scanning protection online threat using one several remotely located server computer client computer may configured determine operational state server computer determine protection status client computer resulting use server computer particular operational state protection status may one least three level indicate vulnerability client computer client computer may determine operational state server computer based available bandwidth network communication client computer server computer client computer may configured allow automatic manual selection another server computer currently selected server computer result client computer protection status threshold level,2
"Disclosed herein are techniques for determining brand safety of a video including image frames and audio content. In some embodiments, frame-level features, scene-level features, and video-level features are extracted by a set of frame-level models, a set of scene-level models, and a set of video-level models, respectively. Outputs from lower level models are used as inputs for higher level models. A brand safety score indicating whether it is safe to associate a brand with the video is determined based on the outputs from the set of video-level models. In some embodiments, commercial content associated with the brand is insert into the video that is determined to be safe for the brand.",disclosed herein technique determining brand safety video including image frame audio content embodiment framelevel feature scenelevel feature videolevel feature extracted set framelevel model set scenelevel model set videolevel model respectively output lower level model used input higher level model brand safety score indicating whether safe associate brand video determined based output set videolevel model embodiment commercial content associated brand insert video determined safe brand,0
"According to one aspect of the present invention, a system and methodology is provided which controls whether or not content is permitted to be transmitted from a source device depending upon the nature of the content and/or other factors more fully described herein. Source devices may include devices such as mobile phones, tablets, netbooks, laptops, desktop computers, and any other devices which are capable of transmitting content which is resident on such device. As an example, inappropriate photographs may be identified by the system of the present invention, and when a user attempts to transmit one or more of these photographs, the system will prevent the user from doing so.",according one aspect present invention system methodology provided control whether content permitted transmitted source device depending upon nature content andor factor fully described herein source device may include device mobile phone tablet netbooks laptop desktop computer device capable transmitting content resident device example inappropriate photograph may identified system present invention user attempt transmit one photograph system prevent user,-1
"Provided is a system for providing a blockchain-based abusing detection service. The system comprises: a user terminal which corresponds to at least one node constituting a blockchain network, generates at least one type of event, and is processed as an abuser when at least one type of event matches a preset abusing pattern; and a detection service providing server including an abusing database unit which maps the at least one type of event to at least one abusing pattern and stores the same, a monitoring unit which monitors whether the at least one type of event generated by the user terminal matches the preset abusing pattern, and a processing unit which processes the user terminal as an abuser when the at least one type of event generated by the user terminal matches the preset abusing pattern. Therefore, the system can detect abusing in real time depending on the type of platform accessed by the user terminal and an event generated thereby, can create blocks constituting a blockchain, and can process the user terminal as an abuser before the blocks are shared.",provided system providing blockchainbased abusing detection service system comprises user terminal corresponds least one node constituting blockchain network generates least one type event processed abuser least one type event match preset abusing pattern detection service providing server including abusing database unit map least one type event least one abusing pattern store monitoring unit monitor whether least one type event generated user terminal match preset abusing pattern processing unit process user terminal abuser least one type event generated user terminal match preset abusing pattern therefore system detect abusing real time depending type platform accessed user terminal event generated thereby create block constituting blockchain process user terminal abuser block shared,-1
"The present invention is related to a machine learning system for cyberbullying detection and prevention on social platforms. As people spend more time utilising technology that keeps them constantly connected to other people, cyberbullying is becoming increasingly common. Cyberbullies can communicate with their victims in a variety of ways, including text messaging, social networking websites, and instant messaging through the internet. Cyberbullying is a significant issue that, like traditional bullying, may make the victim feel inadequate and unduly self-conscious and even lead to suicidal thoughts. Fake news and fake messages are a huge threat to the community since they can lead to theft and commotion, thus calling for the need for cybersecurity. It is paramount to detect and ensure safety across social platforms. This invention proposes an approach to detecting cyberbullying. Out of the three classifiers used decision tree (77.54%), Nave Bayes (73.32%), and SVM (82.12%), SVM was more accurate than the others.",present invention related machine learning system cyberbullying detection prevention social platform people spend time utilising technology keep constantly connected people cyberbullying becoming increasingly common cyberbullies communicate victim variety way including text messaging social networking website instant messaging internet cyberbullying significant issue like traditional bullying may make victim feel inadequate unduly selfconscious even lead suicidal thought fake news fake message huge threat community since lead theft commotion thus calling need cybersecurity paramount detect ensure safety across social platform invention proposes approach detecting cyberbullying three classifier used decision tree nave bayes svm svm accurate others,0
"A method for determining sensitivity-based bias of text includes detecting an input action performed by a user from a plurality of actions, wherein the plurality of actions comprises typing one or more words on a virtual keyboard of a user device and accessing readable content on the user device. When the input action is accessing the readable content on the user device, determining the readable content to be insensitive by parsing the readable content and feeding the parsed readable content to a machine learning (ML) model, wherein the ML model is trained with insensitive datasets of an adversarial database, and presenting a first alert message on the user device before displaying the readable content completely on the user device when the readable content is determined to be insensitive. When the input action is typing the one or more words on the virtual keyboard of the user device, determining the one or more words to be insensitive by parsing the one or more words and feeding the parsed one or more words to the ML model, predicting that a next word to be suggested is insensitive when the one or more words are determined to be insensitive, and performing at least one of presenting a second alert message on the user device when the one or more words are determined to be insensitive, and presenting one or more alternate words for the next word as a suggestion for typing on the user device when the next word is predicted to be insensitive.",method determining sensitivitybased bias text includes detecting input action performed user plurality action wherein plurality action comprises typing one word virtual keyboard user device accessing readable content user device input action accessing readable content user device determining readable content insensitive parsing readable content feeding parsed readable content machine learning model wherein model trained insensitive datasets adversarial database presenting first alert message user device displaying readable content completely user device readable content determined insensitive input action typing one word virtual keyboard user device determining one word insensitive parsing one word feeding parsed one word model predicting next word suggested insensitive one word determined insensitive performing least one presenting second alert message user device one word determined insensitive presenting one alternate word next word suggestion typing user device next word predicted insensitive,0
"The disclosure deals with a system and method for mediating social media platforms automatically for user safety, including in particular for automatically or semi-automatically mediating social media platforms for user safety. People meet on online platforms and discuss a variety of topics. Moderators associated with those platforms play an important role in making the platform convenient and safe to users. This disclosure addresses detecting users who can act as potential moderators of an online group of support seekers and support providers in an online social media platform operating on the Internet. Such users are classified to identify the class of supportive users and class of non-supportive users of an online group. Received suggestions and other acquired data are used to identify a potential moderator for the online group. Acquired data on supportive and non-supportive users, as well as on harmful users, is then automatically supplied to the moderator.",disclosure deal system method mediating social medium platform automatically user safety including particular automatically semiautomatically mediating social medium platform user safety people meet online platform discus variety topic moderator associated platform play important role making platform convenient safe user disclosure address detecting user act potential moderator online group support seeker support provider online social medium platform operating internet user classified identify class supportive user class nonsupportive user online group received suggestion acquired data used identify potential moderator online group acquired data supportive nonsupportive user well harmful user automatically supplied moderator,-1
"The present invention relates to a series of methods and systems in respect of online media content. More specifically, the present invention relates to aspects of fact checking of online media content.",present invention relates series method system respect online medium content specifically present invention relates aspect fact checking online medium content,-1
"The invention discloses a local area network IP address abuse detection device and method, and the device comprises a plurality of external network ports, a display screen, a function key, a warning lamp, a control circuit board, and a loudspeaker. The output ends of the function key and the plurality of external network ports are connected with the input end of the control circuit board; comprising the following steps: step 1, detecting a device network port to access a local area network switch mirror port for the first time; 2, storing the source IP address and the source MAC address analyzed in the step 1 in pairs in a database; 3, confirming a rule template; 4, comparing the IP in the latest ARP table with the IP in the rule template one by one; step 5, comparing the MAC in the latest ARP table with the MAC in the rule template one by one; and step 6, once the violation condition is verified in the step 4 and the step 5, automatically triggering an alarm program and carrying out buzzing alarm. According to the invention, the phenomena of IP address embezzlement, illegal occupation, conflicts and the like can be found in time, and the management and maintenance efficiency of the local area network is improved.",invention discloses local area network address abuse detection device method device comprises plurality external network port display screen function key warning lamp control circuit board loudspeaker output end function key plurality external network port connected input end control circuit board comprising following step step detecting device network port access local area network switch mirror port first time storing source address source mac address analyzed step pair database confirming rule template comparing latest arp table rule template one one step comparing mac latest arp table mac rule template one one step violation condition verified step step automatically triggering alarm program carrying buzzing alarm according invention phenomenon address embezzlement illegal occupation conflict like found time management maintenance efficiency local area network improved,1
"A wireless provisioning device (WPD) is a computer data traffic management system capable of routing TCP/IP traffic using unlicensed spectrum equipment. This WPR is to be strategically placed in logical segment regions within a wireless network to facilitate data traffic management. This device acts to provide connectivity between wireless backbone access points. The device may also be located within customer local area network (LAN) while providing connectivity to a wide area network (WAN). The wireless device has seven total wireless segments. The wireless device is capable of filtering IP addresses, spam, pornographic content, steganographic decryption, controlling firewall and/or routing and/or bridging. The increases effective throughput of TCP/IP traffic over the WAN or LAN while providing for secure management and greater connectivity.",wireless provisioning device wpd computer data traffic management system capable routing tcpip traffic using unlicensed spectrum equipment wpr strategically placed logical segment region within wireless network facilitate data traffic management device act provide connectivity wireless backbone access point device may also located within customer local area network lan providing connectivity wide area network wan wireless device seven total wireless segment wireless device capable filtering address spam pornographic content steganographic decryption controlling firewall andor routing andor bridging increase effective throughput tcpip traffic wan lan providing secure management greater connectivity,-1
"Systems and methods of the present invention provide for detecting and mitigating abuse of unsolicited email or spam. An administrator may select one or more contacts from a list of contacts to opt in to receive an email distribution. An abuse detection software may then determine for each contact in the contact list whether the contact has read the email distribution and reported the email distribution as an unsolicited email message. If so, an abuse department may place a hold on the email distribution (possibly using abuse mitigation software) and display an alert referring the administrator to the abuse department for review of the account. Otherwise, the email distribution may continue to completion.",system method present invention provide detecting mitigating abuse unsolicited email spam administrator may select one contact list contact opt receive email distribution abuse detection software may determine contact contact list whether contact read email distribution reported email distribution unsolicited email message abuse department may place hold email distribution possibly using abuse mitigation software display alert referring administrator abuse department review account otherwise email distribution may continue completion,1
"Disclosed herein are techniques and systems for classifying and moderating text using a machine learning approach that is based on a word embedding process. For instance, word embedding vectors may be used to determine clusters of associated text (e.g., similar words) from a corpus of comments maintained by a remote computing system. The remote computing system may then identify, within the corpus of comments, a subset of comments that include text from a given cluster that was determined, from human labeling input, to include a particular type of word or speech. Using this information, the corpus of comments may be labeled with one of multiple class labels. A machine learning model(s) may be trained to classify text as one of the multiple class labels using a sampled set of labeled comments as training data. At runtime, text can be moderated based on its class label.",disclosed herein technique system classifying moderating text using machine learning approach based word embedding process instance word embedding vector may used determine cluster associated text similar word corpus comment maintained remote computing system remote computing system may identify within corpus comment subset comment include text given cluster determined human labeling input include particular type word speech using information corpus comment may labeled one multiple class label machine learning model may trained classify text one multiple class label using sampled set labeled comment training data runtime text moderated based class label,0
"A system for filtering and managing user's generated textual content on social networks comprising a message screening, message setting, message adjusting and message classifying for the propose of processing the messages are limited in the scope as specified the said system setting wherein the invention objective is to prevent the spreading of undesirable messages on social networks.",system filtering managing user generated textual content social network comprising message screening message setting message adjusting message classifying propose processing message limited scope specified said system setting wherein invention objective prevent spreading undesirable message social network,-1
"A decentralized system for addressing disinformation in news includes a number of nodes connected over a distributed peer-to-peer blockchain-based network, a non-transitory computer-readable storage medium of at least one node having software instructions stored therein, which, when executed by a processor of the at least one node, cause the processor to display, on a display of an electronic device, a newsfeed comprising a number of news items received from one or more publishers, and moderate the content displayed on the display of the electronic device in response to a vote by members of a decentralized autonomous organization (DAO) in which the members of the DAO include the one or more publishers.",decentralized system addressing disinformation news includes number node connected distributed peertopeer blockchainbased network nontransitory computerreadable storage medium least one node software instruction stored therein executed processor least one node cause processor display display electronic device newsfeed comprising number news item received one publisher moderate content displayed display electronic device response vote member decentralized autonomous organization dao member dao include one publisher,-1
"The disclosed embodiment relates to identity verification and identity management, and in particular, to methods and systems for identifying individuals, identifying users accessing one or more services over a network, determining member identity ratings, and based on member identity ratings that restrict access to identity rating-restricted services and certain user-to-user interactions. Further, the user experience in performing identity management is simplified and enhanced as disclosed herein.",disclosed embodiment relates identity verification identity management particular method system identifying individual identifying user accessing one service network determining member identity rating based member identity rating restrict access identity ratingrestricted service certain usertouser interaction user experience performing identity management simplified enhanced disclosed herein,-1
"A filtering system for received content, uses a computer, which receives content to be posted, the computer receiving content from a plurality of different users; the computer including a content filtering system, receiving the content from the plurality of different users, and operating to carry out a first autonomous screening of the content to use rules to determine whether the content meets a posting criteria, and categorizing the content as to whether the autonomous screening indicates that the content has met the posting criteria, the computer further receiving input from a human screening process which carries out humans to screen the criteria; and a machine learning system, that uses differences between the autonomous rules and the results of the human screening to learn from the human screening more about which autonomous rules are properly written, which rules are suspect, and also to create new autonomous rules.",filtering system received content us computer receives content posted computer receiving content plurality different user computer including content filtering system receiving content plurality different user operating carry first autonomous screening content use rule determine whether content meet posting criterion categorizing content whether autonomous screening indicates content met posting criterion computer receiving input human screening process carry human screen criterion machine learning system us difference autonomous rule result human screening learn human screening autonomous rule properly written rule suspect also create new autonomous rule,-1
"A process for protecting children online from sexual predators, contemplated suicide, and premeditated school violence is disclosed: Human female nannys remotely watch computer screens of subscribed children. Using a small cadre of nannys, it is explained why watching large numbers of children is feasible. First, redundancy is introduced to minimize likelihood of a false positive and to ensure no dangerous activity be missed. Next, several forms of time compression are incorporated into the review of children's activities. Further, allocation of nannys to children is expressed mathematically as a covex optimization problem. Review-time of children's activities is thereby minimized with, provably, no better allocation.",process protecting child online sexual predator contemplated suicide premeditated school violence disclosed human female nanny remotely watch computer screen subscribed child using small cadre nanny explained watching large number child feasible first redundancy introduced minimize likelihood false positive ensure dangerous activity missed next several form time compression incorporated review childrens activity allocation nanny child expressed mathematically covex optimization problem reviewtime childrens activity thereby minimized provably better allocation,-1
A meta-model topology comprises a plurality of functions and conforms to a global label schema. A new function not included in the plurality of functions is integrated into the meta-model topology. A particular label of interest that is associated with the new function is identified and the new function is configured such that an output from the new function conforms to an output form corresponding to the particular label of interest from the global label schema. The new function is then integrated into the meta-model topology and the meta-model topology that includes the new function is used to generate a model graph. The model graph is then deployed to a remote application that is configured to receive data prompts comprising input data processed by nodes of the model graph.,metamodel topology comprises plurality function conforms global label schema new function included plurality function integrated metamodel topology particular label interest associated new function identified new function configured output new function conforms output form corresponding particular label interest global label schema new function integrated metamodel topology metamodel topology includes new function used generate model graph model graph deployed remote application configured receive data prompt comprising input data processed node model graph,-1
"A computer-implemented method, computer program product, and system for identifying and altering objectionable media content adapted to identify and alter objectionable data in both incoming and outgoing media content, as well as media content queued for storage in computer-readable memory. The method may be downloaded on a communication device that receives or sends out media content. A proxy, or third party scanning service, provides a recognition software that searches data in the media content to identifying objectionable images, text, video, audio, and voice data. Once the objectionable data is identified, the recognition software alters the identified objectionable data to cover, replace, or delete objectionable images, text, audio, and voice data. The objectionable portion of the data is partially determined by objectionable parameter filters and media transmission filters selected by a user. A non-objectionable portion of the data remains unaltered so that media content remains substantially in its original format. Thus, original media content is viewed with minimal compromise.",computerimplemented method computer program product system identifying altering objectionable medium content adapted identify alter objectionable data incoming outgoing medium content well medium content queued storage computerreadable memory method may downloaded communication device receives sends medium content proxy third party scanning service provides recognition software search data medium content identifying objectionable image text video audio voice data objectionable data identified recognition software alters identified objectionable data cover replace delete objectionable image text audio voice data objectionable portion data partially determined objectionable parameter filter medium transmission filter selected user nonobjectionable portion data remains unaltered medium content remains substantially original format thus original medium content viewed minimal compromise,0
"In some embodiments, a security chatbot comprises a generative language module (GLM) and a prompt manager configured to dynamically update the GLM input prompt according to the output of the GLM. The input prompt instructs the GLM to carry out a task (e.g., determine whether a target message received by a user is indicative of online fraud) and in response, to output a specific flag token. In response to detecting the flag token within the output of the GLM, the prompt manager may selectively execute a code snippet identified according to the respective flag token. Executing the code snippet effectively updates the prompt, which is then fed back to the GLM for the next inference step. In contrast to conventional LLM prompting, updates to the prompt herein comprise modifications (e.g., insertion of other flag tokens, etc.) other than merely appending an inferred token to the previous prompt. Furthermore, the prompt modifications are performed inline, i.e., without submitting an entirely new prompt to the GLM.",embodiment security chatbot comprises generative language module glm prompt manager configured dynamically update glm input prompt according output glm input prompt instructs glm carry task determine whether target message received user indicative online fraud response output specific flag token response detecting flag token within output glm prompt manager may selectively execute code snippet identified according respective flag token executing code snippet effectively update prompt fed back glm next inference step contrast conventional llm prompting update prompt herein comprise modification insertion flag token etc merely appending inferred token previous prompt furthermore prompt modification performed inline without submitting entirely new prompt glm,-1
"In some embodiments, a security chatbot comprises a generative language module (GLM) and a prompt manager configured to dynamically update the GLM input prompt according to the output of the GLM. The input prompt instructs the GLM to carry out a task (e.g., determine whether a target message received by a user is indicative of online fraud) and in response, to output a specific flag token. In response to detecting the flag token within the output of the GLM, the prompt manager may selectively execute a code snippet identified according to the respective flag token. Executing the code snippet effectively updates the prompt, which is then fed back to the GLM for the next inference step. In contrast to conventional LLM prompting, updates to the prompt herein comprise modifications (e.g., insertion of other flag tokens, etc.) other than merely appending an inferred token to the previous prompt. Furthermore, the prompt modifications are performed inline, i.e., without submitting an entirely new prompt to the GLM.",embodiment security chatbot comprises generative language module glm prompt manager configured dynamically update glm input prompt according output glm input prompt instructs glm carry task determine whether target message received user indicative online fraud response output specific flag token response detecting flag token within output glm prompt manager may selectively execute code snippet identified according respective flag token executing code snippet effectively update prompt fed back glm next inference step contrast conventional llm prompting update prompt herein comprise modification insertion flag token etc merely appending inferred token previous prompt furthermore prompt modification performed inline without submitting entirely new prompt glm,-1
"Tools for analyzing images are disclosed. In some cases, the images are analyzed in order to determine whether a particular web site and/or email message is part of an illegitimate online activity. In an aspect, an image analysis process comprises comparing a suspect image with one or more elements of interest (which can include images, words, etc.) by generating fingerprints characterizing the suspect image and the elements of interest, to allow for a quantitative comparison.",tool analyzing image disclosed case image analyzed order determine whether particular web site andor email message part illegitimate online activity aspect image analysis process comprises comparing suspect image one element interest include image word etc generating fingerprint characterizing suspect image element interest allow quantitative comparison,-1
"Electronic appliances, computer-implemented systems, non-transitory media, and methods are provided to identify risky network activities using intelligent algorithms. The appliances, systems, media, and methods enable rapid detection of risky activities.",electronic appliance computerimplemented system nontransitory medium method provided identify risky network activity using intelligent algorithm appliance system medium method enable rapid detection risky activity,-1
"Systems, methods, and media for rating websites for safe advertising are provided. In accordance with some embodiments of the disclosed subject matter, the method comprises: receiving a uniform resource locator corresponding to a webpage; selecting a plurality of evidentiary sources for obtaining evidence relating to the uniform resource locator, wherein each piece of evidence corresponds to one of the plurality of evidentiary sources; converting each piece of evidence obtained from the plurality of evidentiary sources into a plurality of instances that describe the webpage; applying the plurality of instances to a plurality of rating models, wherein each of the plurality of rating models generates an ordinomial and wherein the ordinomial encodes a probability of membership in one or more severity classes of a category; combining the ordinomial from each of the plurality of rating models into a combined ordinomial probability estimate; and generating a rating for the webpage based at least in part on the combined ordinomial probability estimate, wherein the rating identifies whether the webpage is likely to contain objectionable content of the category.",system method medium rating website safe advertising provided accordance embodiment disclosed subject matter method comprises receiving uniform resource locator corresponding webpage selecting plurality evidentiary source obtaining evidence relating uniform resource locator wherein piece evidence corresponds one plurality evidentiary source converting piece evidence obtained plurality evidentiary source plurality instance describe webpage applying plurality instance plurality rating model wherein plurality rating model generates ordinomial wherein ordinomial encodes probability membership one severity class category combining ordinomial plurality rating model combined ordinomial probability estimate generating rating webpage based least part combined ordinomial probability estimate wherein rating identifies whether webpage likely contain objectionable content category,-1
"A system includes one or more memory devices storing instructions, and one or more processors configured to execute the instructions to perform steps of a method for detecting harassment. The system may receive communication data from a first customer service representative terminal or a customer communication device and may determine, based at least in part on the communication data and stored communication data, that the communication data comprises harassing content. The system may, responsive to determining that the communication data comprises harassing content, transmit to a second customer service representative terminal, a notification indicating that the communication data comprises harassing content.",system includes one memory device storing instruction one processor configured execute instruction perform step method detecting harassment system may receive communication data first customer service representative terminal customer communication device may determine based least part communication data stored communication data communication data comprises harassing content system may responsive determining communication data comprises harassing content transmit second customer service representative terminal notification indicating communication data comprises harassing content,-1
"Websites and website users are subject to an increasing array of online threats and attacks. Disclosed herein are, among other things, approaches for protecting websites and website users from online threats. For example, a content server, such as a proxying content delivery network (CDN) server that is delivering content on behalf of an origin server, can modify URLs as they pass through the content server to obscured values that are given to the end-user client browser. The end-user browser can use the obscured URL to obtain content from the content server, but the URL may be valid only for a limited time, and may be invalid for obtaining content from the origin. Hence, information is hidden from the client, making attacks against the website more difficult and frustrating client-end malware that leverages knowledge of browsed URLs.",website website user subject increasing array online threat attack disclosed herein among thing approach protecting website website user online threat example content server proxying content delivery network cdn server delivering content behalf origin server modify url pas content server obscured value given enduser client browser enduser browser use obscured url obtain content content server url may valid limited time may invalid obtaining content origin hence information hidden client making attack website difficult frustrating clientend malware leverage knowledge browsed url,2
"One or more embodiment relates to a video communication device, video communication method, and a video communication mediating method, which are capable of preventing a user in a video communication from being exposed to an inappropriate image or sound from the other party. One or more embodiment may provide a video communication method comprising establishing a first video communication session with a first terminal, consecutively receiving images or sounds from the first terminal through the first video communication session, examining at least a portion of images or sounds received in a period of recent specific time among the received images or sounds, and blocking an output of at least a portion of the received images or sounds or reporting a user of the first terminal as an abusive user to a first server according to the result of the examining.",one embodiment relates video communication device video communication method video communication mediating method capable preventing user video communication exposed inappropriate image sound party one embodiment may provide video communication method comprising establishing first video communication session first terminal consecutively receiving image sound first terminal first video communication session examining least portion image sound received period recent specific time among received image sound blocking output least portion received image sound reporting user first terminal abusive user first server according result examining,-1
"A method of providing a visual feedback system may include providing an application programming interface (API) by which a third party electronic device invokes a visual feedback system. The method may also include receiving, from the third party electronic device, a request to invoke the API, where the request includes information from which an emotional state may be determined. The method may additionally include determining an emotional state associated with the request, and, based on the request, transmitting a visual image associated with the emotional state to the third party electronic device.",method providing visual feedback system may include providing application programming interface api third party electronic device invokes visual feedback system method may also include receiving third party electronic device request invoke api request includes information emotional state may determined method may additionally include determining emotional state associated request based request transmitting visual image associated emotional state third party electronic device,1
"Aspects of an abuse detection system for a web service include an abuse detection engine executing on a server. The abuse detection engine includes a pre-processing module for aggregating a data set for processing and analysis; a suspiciousness test module for identifying suspicious content owners and suspicious users; a graphing module for finding connections between suspicious content owners and suspicious users; an analysis module for determining which groups are constituted of fraudulent or abusive accounts; and a notification generation and output module for generating a list of abusive entities and a notification for output to at least one of: the abusive entity, a digital content distribution company associated with the abusive entity, and a legal department or other entity for further investigation or action. Additionally, royalties for content consumptions associated with abusive accounts may be held. Aspects of an abusive traffic detection method enable multi-account and multi-content owner fraud detection.",aspect abuse detection system web service include abuse detection engine executing server abuse detection engine includes preprocessing module aggregating data set processing analysis suspiciousness test module identifying suspicious content owner suspicious user graphing module finding connection suspicious content owner suspicious user analysis module determining group constituted fraudulent abusive account notification generation output module generating list abusive entity notification output least one abusive entity digital content distribution company associated abusive entity legal department entity investigation action additionally royalty content consumption associated abusive account may held aspect abusive traffic detection method enable multiaccount multicontent owner fraud detection,1
Disclosed are a method for detecting abnormal user groups through activity data analysis and a system thereof. An abuser detection method is for defining abnormal activity through analysis of transaction data in accordance with user activity on content. The abuser detection method comprises the steps of: selecting abnormal user candidates using transaction data for each user; and detecting abnormal user groups having an organizational activity pattern based on activity similarity between the abnormal user candidates.,disclosed method detecting abnormal user group activity data analysis system thereof abuser detection method defining abnormal activity analysis transaction data accordance user activity content abuser detection method comprises step selecting abnormal user candidate using transaction data user detecting abnormal user group organizational activity pattern based activity similarity abnormal user candidate,1
"A method, including recognizing an indicia pattern on an audio signal recognizing its characteristics including but not limited to intensity, pitch, presence of abuse words, utilizing a portable device based sound controller system, prompting one of acceptance and disapproval of the indicia pattern, detecting a present of abuse intent and if intent is present, start taking an action e.g. recording, emailing or flashing an LED.",method including recognizing indicia pattern audio signal recognizing characteristic including limited intensity pitch presence abuse word utilizing portable device based sound controller system prompting one acceptance disapproval indicia pattern detecting present abuse intent intent present start taking action recording emailing flashing led,1
"A method for detecting hate speech and a computing device for performing the method are disclosed.
According to one embodiment, the disclosed hate speech detection method is performed on a computing device comprising one or more processors and memory storing one or more programs executed by the processors.
The method includes a first training phase and a second training phase based on an artificial neural network.

The first training phase includes:

Labeling each word in an input sentence to determine whether it is a hate-speech-related word, and generating a labeling sequence;

Embedding each word in the input sentence to generate a first embedding sequence;

Embedding the labeling sequence to generate a second embedding sequence;

Merging the first and second embedding sequences to generate a merged embedding sequence; and

Using the merged embedding sequence as input to predict the labeling sequence.",method detecting hate speech computing device performing method disclosed according one embodiment disclosed hate speech detection method performed computing device comprising one processor memory storing one program executed processor method includes first training phase second training phase based artificial neural network first training phase includes labeling word input sentence determine whether hatespeechrelated word generating labeling sequence embedding word input sentence generate first embedding sequence embedding labeling sequence generate second embedding sequence merging first second embedding sequence generate merged embedding sequence using merged embedding sequence input predict labeling sequence,0
"Disclosed are a method for detecting abuse based on a blockchain network and a specific blockchain node using the same. The method for detecting abuse based on a blockchain network comprises: a step (a) in which a specific blockchain node among blockchain nodes constituting the blockchain network causes, if service data generated from each service provided by each service providing server is obtained, a smart contract registered in a distributed ledger of the blockchain network to register the service data in the distributed ledger of the blockchain network; and a step (b) in which the specific blockchain node transmits the service data to a pattern analysis server and causes the pattern analysis server to analyze a pattern for each of the service data with reference to a preset pattern analysis criterion to detect abuse, generate abuse detection information, and register the abuse detection information in other blockchain networks, thereby enabling each service providing server to check the abuse detection information.",disclosed method detecting abuse based blockchain network specific blockchain node using method detecting abuse based blockchain network comprises step specific blockchain node among blockchain node constituting blockchain network cause service data generated service provided service providing server obtained smart contract registered distributed ledger blockchain network register service data distributed ledger blockchain network step specific blockchain node transmits service data pattern analysis server cause pattern analysis server analyze pattern service data reference preset pattern analysis criterion detect abuse generate abuse detection information register abuse detection information blockchain network thereby enabling service providing server check abuse detection information,-1
"To prevent the spread of Covid-19 and other contagious diseases, a touchless handshake is able to be implemented using mobile devices. The touchless handshake is able to be performed by sending a signal from one device to another (or to multiple devices) which triggers the device to vibrate to simulate a handshake. Additionally, mobile devices are able to be used to send and/or display a wave/spin.",prevent spread covid contagious disease touchless handshake able implemented using mobile device touchless handshake able performed sending signal one device another multiple device trigger device vibrate simulate handshake additionally mobile device able used send andor display wavespin,-1
"A system and methods is provided that allows participants to assess and construct past, present, and potential future human personas related to themselves, their families, friends, or well-known public personalities. This is done by associating positive, negative, and descriptive attributes to third party or self-actualized avatars. A database holds the aforementioned files for individual attribute selection, persona maps, and therapeutic or motivational response messages used by the system. These elements are cross-indexed to each other to form a system of pre-defined psychosocial construction and pathway improvement programming. The system utilizes various user inputs in order to pull words and/or images for reaction by the user and provide specific content based on user entry and user selection signals.",system method provided allows participant assess construct past present potential future human persona related family friend wellknown public personality done associating positive negative descriptive attribute third party selfactualized avatar database hold aforementioned file individual attribute selection persona map therapeutic motivational response message used system element crossindexed form system predefined psychosocial construction pathway improvement programming system utilizes various user input order pull word andor image reaction user provide specific content based user entry user selection signal,-1
"A system may include: a server comprising a rule cache; a user device communicably coupled to the server; a computer-readable medium comprising instructions that cause the server to: monitor a plurality of third-party data sources; obtain, via a queueing service, a plurality of pieces of content from the plurality of third-party data sources; for each piece of content, fetch a rule ID from a list of rule IDs on the user device, wherein the rule ID is fetched based on the content and a pre-selected setting on the user device; use the rule ID to fetch a rule from the rule cache, the rule comprising a script, the script comprising executable code; execute the script on the piece of content to determine if the piece of content matches the rule; and in response to determining that the piece of content matches the rule, send an alert to the user device.",system may include server comprising rule cache user device communicably coupled server computerreadable medium comprising instruction cause server monitor plurality thirdparty data source obtain via queueing service plurality piece content plurality thirdparty data source piece content fetch rule list rule id user device wherein rule fetched based content preselected setting user device use rule fetch rule rule cache rule comprising script script comprising executable code execute script piece content determine piece content match rule response determining piece content match rule send alert user device,0
"Technology for improving and monitoring data communication security is presented herein. The technology monitors a plurality of sources of risky activities, crawls on computer networks to scan the risky activities, visualizes the risky activities, and detects and prevents risky activities.",technology improving monitoring data communication security presented herein technology monitor plurality source risky activity crawl computer network scan risky activity visualizes risky activity detects prevents risky activity,-1
"Various internet content filtering mechanisms are disclosed. One such mechanism is a filtering service that uses a filter stack and at least two caches. The filter stack can access these caches during its execution of objects. One of the caches could be a cross-user cache that contains information relevant for internet content to a particular user, but this information could be also used by other users. The other cache could be a cross-application cache that contains information relevant for particular applications, but this information could also be used by other applications. The filtering service can be nicely integrated in an operating system to provide a centralized framework for the filtering of internet content.",various internet content filtering mechanism disclosed one mechanism filtering service us filter stack least two cache filter stack access cache execution object one cache could crossuser cache contains information relevant internet content particular user information could also used user cache could crossapplication cache contains information relevant particular application information could also used application filtering service nicely integrated operating system provide centralized framework filtering internet content,-1
"The embodiments of the present invention provide methods and systems for automated collection of human-reviewed data. Requesters send data to be reviewed by humans (or data requests) to a data processing system, which is in communication with one or more systems for collecting human-reviewed data (HRD). The methods and systems discussed enables the data processing system to work with one or more of the systems for collecting HRD). In one embodiment, between the data processing system and the systems for collecting HRD are wrappers, which stores parameters specific to the data requests and libraries for transforming the data requests to human intelligent tasks (HITs) specific to each HRD system. The data processing system also includes a number of components that facilitate transforming data requests into HITs, sending the HITs to the HRD collection systems, receiving HRD, and analyzing HRD to improve the quality of collected HRD.",embodiment present invention provide method system automated collection humanreviewed data requester send data reviewed human data request data processing system communication one system collecting humanreviewed data hrd method system discussed enables data processing system work one system collecting hrd one embodiment data processing system system collecting hrd wrapper store parameter specific data request library transforming data request human intelligent task hit specific hrd system data processing system also includes number component facilitate transforming data request hit sending hit hrd collection system receiving hrd analyzing hrd improve quality collected hrd,-1
"Systems and methods are disclosed for reporting spam detected in a communication network. Entities in the network detect that an electronic message comprises spam, and generate a spam report for the electronic message. The spam report is in a format that is enhanced with newly-defined fields. A spam center in the network receives the spam reports from the entities, and processes the spam reports to generate spam rules for detecting spam in electronic messages transported over the communication network. The spam center then selectively distributes the spam rules to one or more of the entities of the communication network based on an analysis of the spam reports. The entities may then use the spam rules to detect spam in other electronic messages that are transported over the communication network.",system method disclosed reporting spam detected communication network entity network detect electronic message comprises spam generate spam report electronic message spam report format enhanced newlydefined field spam center network receives spam report entity process spam report generate spam rule detecting spam electronic message transported communication network spam center selectively distributes spam rule one entity communication network based analysis spam report entity may use spam rule detect spam electronic message transported communication network,-1
"According to one embodiment of the present invention, in a method for blocking digital abuse performed by an electronic device with a keyboard application installed, which transmits a user's input via a user input interface to a metaverse environment:

(a) When the keyboard application is invoked by the metaverse environment or the operating system controlling it, the electronic device provides the user input interface to the user to receive input;

(b) The electronic device receives the user's input through the user input interface;

(c) The electronic device generates input information based on the user's input;

(d) The electronic device determines whether the input information includes abusive content by referencing an abuse policy database (DB) corresponding to the input information and the applications identification information;

(e) If the input information includes abusive content, the electronic device controls the input accordingly.

This allows for early detection of digital abusive behavior by users. As a result, victims can respond quickly, and perpetrators can be promptly identified.

Let me know if youd like this rewritten in a more formal, academic, or patent-appropriate tone.









Ask ChatGPT
",according one embodiment present invention method blocking digital abuse performed electronic device keyboard application installed transmits user input via user input interface metaverse environment keyboard application invoked metaverse environment operating system controlling electronic device provides user input interface user receive input electronic device receives user input user input interface electronic device generates input information based user input electronic device determines whether input information includes abusive content referencing abuse policy database corresponding input information application identification information input information includes abusive content electronic device control input accordingly allows early detection digital abusive behavior user result victim respond quickly perpetrator promptly identified let know youd like rewritten formal academic patentappropriate tone ask chatgpt,1
"A server that manages download and/or distribution of content may collect content-related information associated with users, and classify the users based on that data. The content-related information may comprise data relating to content generation and/or upload by the users. The server may determine whether a user is granted permission to upload content for distribution or download via the server, based on correlating the user with a previously classified user, and/or on evaluation of current content generation or download activities associated with the user. Determination of whether the user is granted permission to upload content may be done directly and/or autonomously by the server. Alternatively, a recommendation whether to grant permission to upload content may be submitted by the server to another entity for selection thereby. The server may reject or accept a content upload request from the user based on the determination of whether the user is granted permission.",server manages download andor distribution content may collect contentrelated information associated user classify user based data contentrelated information may comprise data relating content generation andor upload user server may determine whether user granted permission upload content distribution download via server based correlating user previously classified user andor evaluation current content generation download activity associated user determination whether user granted permission upload content may done directly andor autonomously server alternatively recommendation whether grant permission upload content may submitted server another entity selection thereby server may reject accept content upload request user based determination whether user granted permission,-1
"A method for selecting advertisement spots. The method comprises certifying a digital document having a placeholder for at least one advertisement, identifying at least one characteristic indicative of appropriateness of the digital document, assigning an appropriateness score to the digital document according to the at least one characteristic and associating a digital certificate indicative of the appropriateness score with the digital document, wherein the digital certificate is used for associating an advertisement with the placeholder.",method selecting advertisement spot method comprises certifying digital document placeholder least one advertisement identifying least one characteristic indicative appropriateness digital document assigning appropriateness score digital document according least one characteristic associating digital certificate indicative appropriateness score digital document wherein digital certificate used associating advertisement placeholder,-1
"To protect a user of a social network, the user's activity is monitored during a baseline monitoring period to determine a baseline activity record. If subsequently monitored activity of the user deviates sufficiently from the baseline activity record to indicate abuse (hijacking) of the user's account, the abuse is mitigated, for example by notifying the user of the abuse. Monitored activity includes posting links, updating statuses, sending messages, and changing a profile. Monitoring also includes logging times of the user activity. Monitoring anomalous profile changes does not need a baseline.",protect user social network user activity monitored baseline monitoring period determine baseline activity record subsequently monitored activity user deviate sufficiently baseline activity record indicate abuse hijacking user account abuse mitigated example notifying user abuse monitored activity includes posting link updating status sending message changing profile monitoring also includes logging time user activity monitoring anomalous profile change need baseline,-1
"Techniques are described that determine when content to be shared by a user may be offensive, and providing the user with a notification that the content may be offensive. In some examples, the user may be provided with a notification that includes a selectable option allowing the user to withdraw or undo the content from being shared, additional information regarding why the content was determined to be offensive, content sharing guidelines, and/or advice for how to revise the content to be less offensive. In some examples, the notification may be presented for a predetermined period of time, and the content may be held in a pending state and not shared with other users until expiration of the predetermined period.",technique described determine content shared user may offensive providing user notification content may offensive example user may provided notification includes selectable option allowing user withdraw undo content shared additional information regarding content determined offensive content sharing guideline andor advice revise content less offensive example notification may presented predetermined period time content may held pending state shared user expiration predetermined period,-1
"One embodiment of the present invention provides a system for stable selection of collaborating partners for exchanging security data. During operation, the system receives vectors of collaboration values from a plurality of entities. A collaboration value is a measure of an expected benefit of collaborating with a respective entity. The system sorts each of the vectors by the collaboration values of the respective vector. The system then determines matching entities given a number of partners wanted by each organization in N. The system may add matching entities to lists of collaborating partners given the number of partners wanted by each organization in N. Subsequently, the system sends the lists of collaborating partners to facilitate exchanging security data with partners in the list of collaborating partners.",one embodiment present invention provides system stable selection collaborating partner exchanging security data operation system receives vector collaboration value plurality entity collaboration value measure expected benefit collaborating respective entity system sort vector collaboration value respective vector system determines matching entity given number partner wanted organization system may add matching entity list collaborating partner given number partner wanted organization subsequently system sends list collaborating partner facilitate exchanging security data partner list collaborating partner,-1
"A system and method for accelerating an automated labeling of a volume of unlabeled digital event data samples includes identifying a corpus characteristic of a digital event data corpus that includes a plurality of distinct unlabeled digital event data samples; selecting an automated bulk labeling algorithm based on the corpus characteristic associated with the digital event data corpus satisfying a bulk labeling criterion of the automated bulk labeling algorithm; evaluating a subset of the plurality of unlabeled digital event data samples, wherein evaluating the subset includes attributing a distinct classification label to each digital event data sample within the subset; and in response to the selection, executing the selected automated bulk labeling algorithm against the digital event data corpus, wherein the executing includes simultaneously assigning a classification label equivalent to the distinct classification label to a superset of the digital event data corpus that relates to the subset.",system method accelerating automated labeling volume unlabeled digital event data sample includes identifying corpus characteristic digital event data corpus includes plurality distinct unlabeled digital event data sample selecting automated bulk labeling algorithm based corpus characteristic associated digital event data corpus satisfying bulk labeling criterion automated bulk labeling algorithm evaluating subset plurality unlabeled digital event data sample wherein evaluating subset includes attributing distinct classification label digital event data sample within subset response selection executing selected automated bulk labeling algorithm digital event data corpus wherein executing includes simultaneously assigning classification label equivalent distinct classification label superset digital event data corpus relates subset,-1
"The present invention relates to a device and a method for real-time deep-learning-based anomaly detection to prevent crimes on metaverse. The device comprises: a prohibited sentence extraction unit which filters prohibited sentences by applying a dictionary of prohibited words which are extracted from hate speech data to at least one piece of real-time conversation data from among voice conversations and chat conversations between users; an anomaly action detection unit which detects anomaly actions in the users' actions through an anomaly action detection model when the prohibited sentences are detected; an anomaly sentence detection unit which detects anomaly sentences in the prohibited sentences using an anomaly sentence detection model when the prohibited sentences are detected; and an anomaly recognition performance unit which calculates an anomaly perception index (API) for anomaly detection based on the detection result of the prohibited sentences and the detection result of each of the anomaly actions and the anomaly sentences. According to the present invention, real-time detection can be performed quickly and efficiently.",present invention relates device method realtime deeplearningbased anomaly detection prevent crime metaverse device comprises prohibited sentence extraction unit filter prohibited sentence applying dictionary prohibited word extracted hate speech data least one piece realtime conversation data among voice conversation chat conversation user anomaly action detection unit detects anomaly action user action anomaly action detection model prohibited sentence detected anomaly sentence detection unit detects anomaly sentence prohibited sentence using anomaly sentence detection model prohibited sentence detected anomaly recognition performance unit calculates anomaly perception index api anomaly detection based detection result prohibited sentence detection result anomaly action anomaly sentence according present invention realtime detection performed quickly efficiently,0
"Technology for providing reporting options specific for a market or a common user attribute is disclosed herein. A computer server of a social networking system determines multiple community standards for a group of users of a social networking system, wherein the group of users have a common user attribute such as a common market. The computer server receives a request for reporting a content object in the social networking system from a user among the group of users. The computer server determines multiple reporting options based on the community standards, and transmits the reporting options to the user in response to the request. The reporting options represent potential reasons why the user reports the content object",technology providing reporting option specific market common user attribute disclosed herein computer server social networking system determines multiple community standard group user social networking system wherein group user common user attribute common market computer server receives request reporting content object social networking system user among group user computer server determines multiple reporting option based community standard transmits reporting option user response request reporting option represent potential reason user report content object,-1
"The method of assessing the validity of factual claims determines if a purported factual claim, such as a statement made on social media, in the news, etc., is ""true"", ""false"" or ""unknown"" through comparison with corresponding ranked factual claims stored in a comparison database (102). The comparison database (102) is assembled by storing a plurality of sets of digital content items, where each of the sets of digital content items has a unique topic. Factual claims within each set are ranked by the number of agreements between individual items within each set. A query item to be assessed is input, and at least one purported factual claim to be assessed is extracted. This purported factual claim is compared against a predetermined number of highest-ranking factual claims within the corresponding set. A validity score is then generated based on the number of agreements and the number of disagreements from the comparison.",method assessing validity factual claim determines purported factual claim statement made social medium news etc true false unknown comparison corresponding ranked factual claim stored comparison database comparison database assembled storing plurality set digital content item set digital content item unique topic factual claim within set ranked number agreement individual item within set query item assessed input least one purported factual claim assessed extracted purported factual claim compared predetermined number highestranking factual claim within corresponding set validity score generated based number agreement number disagreement comparison,-1
"The present invention relates to a sentence generation method for generating sentences excluding hate speech in a sentence generation device. The method comprises:

Receiving a conversational sentence;

Generating a response sentence to the conversational sentence using a pre-trained first language model;

Detecting whether hate speech is present in the generated response sentence using a pre-trained hate speech classification model; and

If the hate speech classification model detects the presence of hate speech, generating a new response sentence excluding the hate speech using a pre-trained second language model.

Through this method, the performance of the language model can be maintained while excluding hate speech, and the sentence generation speed can be improved.
",present invention relates sentence generation method generating sentence excluding hate speech sentence generation device method comprises receiving conversational sentence generating response sentence conversational sentence using pretrained first language model detecting whether hate speech present generated response sentence using pretrained hate speech classification model hate speech classification model detects presence hate speech generating new response sentence excluding hate speech using pretrained second language model method performance language model maintained excluding hate speech sentence generation speed improved,0
"The disclosed computer-implemented method for performing security actions based on people's actual reactions to interactions may include (i) detecting an interaction (e.g., an interaction with a digital communication) of a monitored person (e.g., a child), (ii) estimating the monitored person's expected reaction to the interaction, (iii) using contemporaneous sensor data to estimate the monitored person's actual reaction to the interaction, and (iv) performing a security action based at least in part on a comparison of the monitored person's expected reaction and the monitored person's actual reaction. Various other methods, systems, and computer-readable media are also disclosed.",disclosed computerimplemented method performing security action based people actual reaction interaction may include detecting interaction interaction digital communication monitored person child estimating monitored person expected reaction interaction iii using contemporaneous sensor data estimate monitored person actual reaction interaction performing security action based least part comparison monitored person expected reaction monitored person actual reaction various method system computerreadable medium also disclosed,-1
"A method, computer system, and a computer program product for propagating a recording are provided. A recording is received from a user computer. The received recording is analyzed. In response to determining based upon the analysis of the received recording that at least a portion of the recording is suitable for propagation, the portion of the recording is transmitted to a venue for playing of the portion. In response to the transmitting of the portion of the recording, a confirmation message is transmitted to the user computer.",method computer system computer program product propagating recording provided recording received user computer received recording analyzed response determining based upon analysis received recording least portion recording suitable propagation portion recording transmitted venue playing portion response transmitting portion recording confirmation message transmitted user computer,0
"Video submission survey reviewer device, system, process, and computer program product capable of recording campaign or survey content including video, analyzing the recorded content, and synthesizing information about the recorded content to provide improved and more efficient analysis or curation and presentation of the processed data and its associated information.",video submission survey reviewer device system process computer program product capable recording campaign survey content including video analyzing recorded content synthesizing information recorded content provide improved efficient analysis curation presentation processed data associated information,0
"Abuse of a content-sharing service is detected by an arrangement in which an in-memory cache is distributed among a plurality of nodes, such as front-end web servers, and which caches each item accessed by users of the service as a single instance in the distributed cache. Associated with each cached item is a unit of metadata which functions as a counter that is automatically incremented each time the item is served from the distributed cache. Because abusive items often tend to become quickly popular for downloading, when the counter exceeds a predetermined threshold over a given time interval, it is indicative of an access rate that makes the item a candidate for being deemed abusive. A reference to the item and its access count are responsively written to a persistent store such as a log file or database.",abuse contentsharing service detected arrangement inmemory cache distributed among plurality node frontend web server cache item accessed user service single instance distributed cache associated cached item unit metadata function counter automatically incremented time item served distributed cache abusive item often tend become quickly popular downloading counter exceeds predetermined threshold given time interval indicative access rate make item candidate deemed abusive reference item access count responsively written persistent store log file database,1
"Aspects of the invention include identifying a user at an electronic device and accessing a profile of the user. The profile includes previously displayed data flagged as causing a negative reaction by the user when displayed to the user. New data for display is received at the electronic device. The new data is analyzed to determine whether it includes at least a subset of the previously displayed data flagged as causing a negative reaction by the user. The new data is displayed on a display of the electronic device based on determining that the new data does not include at least a subset of the previously displayed data flagged as causing a negative reaction. Otherwise, the new data is modified by removing the at least a subset of the previously displayed data from the new data and the modified data is displayed on the display of the electronic device.",aspect invention include identifying user electronic device accessing profile user profile includes previously displayed data flagged causing negative reaction user displayed user new data display received electronic device new data analyzed determine whether includes least subset previously displayed data flagged causing negative reaction user new data displayed display electronic device based determining new data include least subset previously displayed data flagged causing negative reaction otherwise new data modified removing least subset previously displayed data new data modified data displayed display electronic device,-1
"An apparatus comprises at least one processing device comprising a processor coupled to a memory. The processing device is configured to identify artifacts in a plurality of messages of an account of a user, and to replace the identified artifacts in the messages with respective modified artifacts while also maintaining in access-controlled storage at least information related to the identified artifacts. The processing device receives from a requestor a request for a given one of the identified artifacts that has been replaced with a corresponding modified artifact, determines a profile of the requestor based at least in part on the request, makes a security determination based at least in part on the determined profile, and takes at least one automated action based at least in part on the security determination.",apparatus comprises least one processing device comprising processor coupled memory processing device configured identify artifact plurality message account user replace identified artifact message respective modified artifact also maintaining accesscontrolled storage least information related identified artifact processing device receives requestor request given one identified artifact replaced corresponding modified artifact determines profile requestor based least part request make security determination based least part determined profile take least one automated action based least part security determination,-1
"A method for creating and exchanging a copyright for each artificial intelligence (AI)-generated multimedia is described. An AI model and a reference input for a multimedia is received from a user. If the reference input complies with system policies, an AI-generated multimedia is generated from the reference input using the AI model. The AI-generated multimedia is compared against works of a same type in a blockchain and decentralized file storage and if the AI-generated multimedia fails to match the works, the AI-generated multimedia is categorized as having originality. A copyright for the AI-generated multimedia and the AI-generated multimedia is stored. An exchange is facilitated with a buyer using cryptocurrency and is written to a blockchain.",method creating exchanging copyright artificial intelligence aigenerated multimedia described model reference input multimedia received user reference input complies system policy aigenerated multimedia generated reference input using model aigenerated multimedia compared work type blockchain decentralized file storage aigenerated multimedia fails match work aigenerated multimedia categorized originality copyright aigenerated multimedia aigenerated multimedia stored exchange facilitated buyer using cryptocurrency written blockchain,0
"A system and method for fast-detection and mitigation of emerging network fraud attacks includes sourcing digital event data samples associated with one or more online services; executing graph-rendering computer instructions that automatically construct a backbone graph using a subset of features extracted from the sourced digital event data samples, wherein the constructing includes: identifying, as graphical nodes, a first plurality of distinct features of the subset of features; identifying, as graphical edges, a second plurality of distinct features of the subset of features; generating a graphical edge between distinct pairs of graphical nodes comprising a same type of feature of the subset of features based on feature values associated with at least one distinct feature of the second plurality of distinct features; and mitigating, via a digital threat mitigation action, if one or more emerging network fraud attacks is identified based on an assessment of a cluster of networked nodes.",system method fastdetection mitigation emerging network fraud attack includes sourcing digital event data sample associated one online service executing graphrendering computer instruction automatically construct backbone graph using subset feature extracted sourced digital event data sample wherein constructing includes identifying graphical node first plurality distinct feature subset feature identifying graphical edge second plurality distinct feature subset feature generating graphical edge distinct pair graphical node comprising type feature subset feature based feature value associated least one distinct feature second plurality distinct feature mitigating via digital threat mitigation action one emerging network fraud attack identified based assessment cluster networked node,2
"Techniques are described that determine when content to be shared by a user may be offensive, and providing the user with a notification that the content may be offensive. In some examples, the user may be provided with a notification that includes a selectable option allowing the user to withdraw or undo the content from being shared, additional information regarding why the content was determined to be offensive, content sharing guidelines, and/or advice for how to revise the content to be less offensive. In some examples, the notification may be presented for a predetermined period of time, and the content may be held in a pending state and not shared with other users until expiration of the predetermined period.",technique described determine content shared user may offensive providing user notification content may offensive example user may provided notification includes selectable option allowing user withdraw undo content shared additional information regarding content determined offensive content sharing guideline andor advice revise content less offensive example notification may presented predetermined period time content may held pending state shared user expiration predetermined period,-1
"A method for monitoring online security threats comprising of a machine-learning service that receives data related to a plurality of features related to internet traffic metrics, the service then processes said data by performing operations selected from among: an operation of ranking at least one feature, an operation of classifying at least one feature, an operation of predicting at least one feature, and an operation of clustering at least one feature, and as a result the machine learning service outputs metrics that aid in the detection, identification, and prediction of an attack.",method monitoring online security threat comprising machinelearning service receives data related plurality feature related internet traffic metric service process said data performing operation selected among operation ranking least one feature operation classifying least one feature operation predicting least one feature operation clustering least one feature result machine learning service output metric aid detection identification prediction attack,2
"Some embodiments employ a consensus-building procedure to train a multitask graph comprising a plurality of nodes interconnected by a plurality of edges, wherein each node is associated with a task of determining a set of node-specific attributes of a set of input data, and each edge comprises an AI module (e.g., neural network) configured to determine attributes of an end node according to attributes of a start node of the respective edge. Training fosters consensus between all edges converging to a node. The trained multitask graph may then be deployed in a threat detector configured to determine whether an input set of data is indicative of malice (e.g., malware, intrusion, online threat, etc.).",embodiment employ consensusbuilding procedure train multitask graph comprising plurality node interconnected plurality edge wherein node associated task determining set nodespecific attribute set input data edge comprises module neural network configured determine attribute end node according attribute start node respective edge training foster consensus edge converging node trained multitask graph may deployed threat detector configured determine whether input set data indicative malice malware intrusion online threat etc,2
"A system for use with an artificial intelligence (AI) model configured to accept text input, such as generative pre-trained transformer (GPT), that detects and tags trusted instructions and nontrusted instructions of an input provided by a user responsive to an AI model prompt. The system uses reinforcement learning (RL) and a set of rules to remove the untrusted instructions from the input and provide only trusted instructions to the AI model. The input is represented as tokens, wherein the trusted instructions and the untrusted instructions are represented using incompatible token sets.",system use artificial intelligence model configured accept text input generative pretrained transformer gpt detects tag trusted instruction nontrusted instruction input provided user responsive model prompt system us reinforcement learning set rule remove untrusted instruction input provide trusted instruction model input represented token wherein trusted instruction untrusted instruction represented using incompatible token set,-1
Disclosed are a method and a system for blocking continuous input of similar comments. An abuser detection method comprises the steps of: performing embedding for each of sentences input as a comment into a vector for a plurality of comments continuously input or input within a predetermined interval during a unit time; calculating a similarity between sentences input as comments using the embedded vector; and determining whether to abuse the plurality of comments using the similarity between the sentences.,disclosed method system blocking continuous input similar comment abuser detection method comprises step performing embedding sentence input comment vector plurality comment continuously input input within predetermined interval unit time calculating similarity sentence input comment using embedded vector determining whether abuse plurality comment using similarity sentence,0
A model graph receives a data prompt as input. The data prompt is segmented into multiple segments. An instance of the model graph is generated for each segment of the data prompt. Each instance of the model graph is also pruned according to policy information associated with the model graph instance's corresponding data prompt segment. Each instance of the model graph generates an intermediary output. A final output of the model graph for the entire data prompt is generated based on a combination of the intermediary outputs.,model graph receives data prompt input data prompt segmented multiple segment instance model graph generated segment data prompt instance model graph also pruned according policy information associated model graph instance corresponding data prompt segment instance model graph generates intermediary output final output model graph entire data prompt generated based combination intermediary output,-1
"Apparatuses, components, methods, and techniques for classifying content are provided. An example method classifies textual content as objectionable. Another example identifies relevant attributes for the content. The example method includes analyzing a body of the content to determine a level of similarity between text in the content and a corpus of predetermined content. The example method further includes upon determining that the level of similarity is greater than a predefined threshold using natural language processing to extract a plurality of features from the content, the features being associated with concepts related to the body of the content. The example method further includes analyzing the extracted features to determine a second level of similarity between the content and the corpus of predetermined content. The example method further includes upon determining that the second level of similarity is greater than a second predefined threshold, classifying the content as objectionable.",apparatus component method technique classifying content provided example method classifies textual content objectionable another example identifies relevant attribute content example method includes analyzing body content determine level similarity text content corpus predetermined content example method includes upon determining level similarity greater predefined threshold using natural language processing extract plurality feature content feature associated concept related body content example method includes analyzing extracted feature determine second level similarity content corpus predetermined content example method includes upon determining second level similarity greater second predefined threshold classifying content objectionable,0
"System and method are provided for identification and classification of multilingual messages that would be considered inappropriate in an online interactive portal. The system may include processors to generate a set of data of intended inappropriate multilingual messages to train classification model. The set of data with labels is classified by assigning unique identifiers. The system includes pre-processing module to eliminate unwanted characters from set of data to train classification model. The classification model may be trained by multilingual representation module based at least in part on set of data with labels. The classification model determines whether set of data with one or more labels includes intended inappropriate multilingual messages. Furthermore, feedback loop module is utilised to retrain classification model recurrently to update set of data. The system is formed on Convolutional Neural Network (CNN) configured to classify multilingual messages as inappropriate in online interactive portal.",system method provided identification classification multilingual message would considered inappropriate online interactive portal system may include processor generate set data intended inappropriate multilingual message train classification model set data label classified assigning unique identifier system includes preprocessing module eliminate unwanted character set data train classification model classification model may trained multilingual representation module based least part set data label classification model determines whether set data one label includes intended inappropriate multilingual message furthermore feedback loop module utilised retrain classification model recurrently update set data system formed convolutional neural network cnn configured classify multilingual message inappropriate online interactive portal,0
"Aspects of the subject disclosure may include, for example, receiving, by a processing system including a processor via a satellite, an emergency communication that was transmitted from an end user device to the satellite; and determining, by the processing system, a legitimacy of the emergency communication according to an analysis based on various information such as a diligence query or challenge sent to the end user device by the satellite, a history of emergency communications associated with the end user device, a location of the end user device, a location of an emergency event associated with the emergency communication, a number of other emergency communications from other end user devices that are associated with the emergency event, a time period of the other emergency communications, locations of the other end user devices, or a combination thereof. Other embodiments are disclosed.",aspect subject disclosure may include example receiving processing system including processor via satellite emergency communication transmitted end user device satellite determining processing system legitimacy emergency communication according analysis based various information diligence query challenge sent end user device satellite history emergency communication associated end user device location end user device location emergency event associated emergency communication number emergency communication end user device associated emergency event time period emergency communication location end user device combination thereof embodiment disclosed,-1
"The present invention relates to an integrated management method for multiple closed circuit televisions (CCTVs) performed by a CCTV integrated management device. The method comprises the steps of: receiving user authentication information or administrator authentication information from a user terminal or an administrator terminal; and providing at least one of a password security function, an asset management function, and an abuse detection function for the multiple CCTVs to the user terminal or the administrator terminal based on the user authentication information or the administrator authentication information.",present invention relates integrated management method multiple closed circuit television cctvs performed cctv integrated management device method comprises step receiving user authentication information administrator authentication information user terminal administrator terminal providing least one password security function asset management function abuse detection function multiple cctvs user terminal administrator terminal based user authentication information administrator authentication information,-1
A meta-model topology comprises a plurality of functions and conforms to a global label schema. A new function not included in the plurality of functions is integrated into the meta-model topology. A particular label of interest that is associated with the new function is identified and the new function is configured such that an output from the new function conforms to an output form corresponding to the particular label of interest from the global label schema. The new function is then integrated into the meta-model topology and the meta-model topology that includes the new function is used to generate a model graph. The model graph is then deployed to a remote application that is configured to receive data prompts comprising input data processed by nodes of the model graph.,metamodel topology comprises plurality function conforms global label schema new function included plurality function integrated metamodel topology particular label interest associated new function identified new function configured output new function conforms output form corresponding particular label interest global label schema new function integrated metamodel topology metamodel topology includes new function used generate model graph model graph deployed remote application configured receive data prompt comprising input data processed node model graph,-1
"Systems and methods for gathering, classifying, and evaluating real time security intelligence data concerning security threats presented by an IP address, and reporting in real time the degree and character of such security threats.",system method gathering classifying evaluating real time security intelligence data concerning security threat presented address reporting real time degree character security threat,2
"A system for addressing disinformation in news includes a non-transitory computer-readable storage medium having software instructions stored therein, which, when executed by a processor, cause the processor to display, on a display of an electronic device, a content feed comprising a series of news items, such as news articles and other news media, received from one or more news organizations, and restrict the electronic device from publishing news articles to the content without prior authorization, such as vetting.",system addressing disinformation news includes nontransitory computerreadable storage medium software instruction stored therein executed processor cause processor display display electronic device content feed comprising series news item news article news medium received one news organization restrict electronic device publishing news article content without prior authorization vetting,0
To provide a method and system for detecting an abuse sales channel in a decentralized online reservation system.SOLUTION: An abuse detection method comprises: generating a block for decentralized processing of a trading transaction associated with a trading request for a reserved commodity of a seller in a blockchain network in which multiple sales channels having a sales right for the reserved commodity are participated; and detecting an abuse channel from the multiple sales channels by using a difference between when the block was generated and when the trading transaction in the block was generated.SELECTED DRAWING: Figure 5,provide method system detecting abuse sale channel decentralized online reservation systemsolution abuse detection method comprises generating block decentralized processing trading transaction associated trading request reserved commodity seller blockchain network multiple sale channel sale right reserved commodity participated detecting abuse channel multiple sale channel using difference block generated trading transaction block generatedselected drawing figure,-1
"Devices, systems, and methods for allowing parents to view and track smart phone activities of their children can include one or more child software modules. The module can be installed on each child's smart phone. The module can access and extract data from or about more than one of the smart phone's other software applications, including at least two of the following: a texting application, a social media application, an image application that facilitates transmission or reception of images, and a web browser application. The module can further send the extracted data to an analysis server. The module can also monitor location data. Moreover, the system can include an analysis server that can identify potentially harmful language, images, and websites. Further, the system can include a parent portal. The parent portal can receive results from the analysis server.",device system method allowing parent view track smart phone activity child include one child software module module installed child smart phone module access extract data one smart phone software application including least two following texting application social medium application image application facilitates transmission reception image web browser application module send extracted data analysis server module also monitor location data moreover system include analysis server identify potentially harmful language image website system include parent portal parent portal receive result analysis server,1
"A video call mediation method of a system may include receiving, by a server, a mediation request, from a plurality of mobiles, mediating, by the server, a first mobile and a second mobile, of the plurality of mobiles, establishing, by the first mobile and the second mobile, a video call session, receiving, by the first mobile, a video, from the second mobile, through the video call session, detecting, by the first mobile, a certain input, reporting, by the first mobile, a video received in the server, in response to the certain input, ending, by the first mobile, the video call session with the second mobile, and establishing, by the first mobile, a video call session with a third mobile, and verifying, by the server, the reporting, and rejecting, by the server, additional mediation request of the second mobile.",video call mediation method system may include receiving server mediation request plurality mobile mediating server first mobile second mobile plurality mobile establishing first mobile second mobile video call session receiving first mobile video second mobile video call session detecting first mobile certain input reporting first mobile video received server response certain input ending first mobile video call session second mobile establishing first mobile video call session third mobile verifying server reporting rejecting server additional mediation request second mobile,-1
"Embodiments of the present disclosure include systems and methods for producing a user interface based on identified changes in expressions over time in a media content. The methods can comprise receiving, from a user, the media content corresponding to one or more individuals and displaying the user interface, where the user interface comprises a media region that presents the media content and an expression tracking region. The method may further include predicting, using one or more neural networks, one or more expressions associated with the one or more individuals based on the media content, updating the expression tracking region based on the predicted one or more expressions to identify changes in the one or more expressions over time based on the media content, and annotating the media region of the user interface based on the identified changes in the one or more expressions over time.",embodiment present disclosure include system method producing user interface based identified change expression time medium content method comprise receiving user medium content corresponding one individual displaying user interface user interface comprises medium region present medium content expression tracking region method may include predicting using one neural network one expression associated one individual based medium content updating expression tracking region based predicted one expression identify change one expression time based medium content annotating medium region user interface based identified change one expression time,0
"Devices, systems, and methods for allowing parents to view and track smart phone activities of their children can include one or more child software modules. The module can be installed on each child's smart phone. The module can access and extract data from or about more than one of the smart phone's other software applications, including at least two of the following: a texting application, a social media application, an image application that facilitates transmission or reception of images, and a web browser application. The module can further send the extracted data to an analysis server. The module can also monitor location data. Moreover, the system can include an analysis server that can identify potentially harmful language, images, and websites. Further, the system can include a parent portal. The parent portal can receive results from the analysis server.",device system method allowing parent view track smart phone activity child include one child software module module installed child smart phone module access extract data one smart phone software application including least two following texting application social medium application image application facilitates transmission reception image web browser application module send extracted data analysis server module also monitor location data moreover system include analysis server identify potentially harmful language image website system include parent portal parent portal receive result analysis server,1
"Systems and methods include implementing a remote machine learning service that collects digital event data; collecting incumbent digital threat scores generated by an incumbent machine learning model and successor digital threat scores generated by a successor digital threat machine learning (ML) model; implementing anomalous-shift-detection that detects whether the successor digital threat scores of the successor digital threat ML model produces an anomalous shift; if the anomalous shift is detected by the machine learning model validation system, blocking a deployment of the successor digital threat model to a live ensemble of digital threat scoring models; or if the anomalous shift is not detected by the machine learning model validation system, deploying the successor digital threat ML model by replacing the incumbent digital threat ML model in a live ensemble of digital threat scoring models with the successor digital threat ML model.",system method include implementing remote machine learning service collect digital event data collecting incumbent digital threat score generated incumbent machine learning model successor digital threat score generated successor digital threat machine learning model implementing anomalousshiftdetection detects whether successor digital threat score successor digital threat model produce anomalous shift anomalous shift detected machine learning model validation system blocking deployment successor digital threat model live ensemble digital threat scoring model anomalous shift detected machine learning model validation system deploying successor digital threat model replacing incumbent digital threat model live ensemble digital threat scoring model successor digital threat model,2
"A computer-implemented method of managing security services for one or more cloud computing platforms is disclosed. The method comprises receiving, by a main controller, a security policy from a client device, the client device being associated with a set of computing applications hosted by one or more independent, private virtual clusters on one or more cloud computing platforms, the main controller residing outside the one or more virtual clusters, each of the one or more virtual clusters to be served by a security gateway system residing within the one or more cloud computing platforms, the security policy indicating how threat intelligence data is to be applied to the set of computing applications with respect to a plurality of application scopes; receiving application data from the client device, the application data indicating whether a specific computing application of the set of computing applications has one or more application properties of a plurality of application properties, the plurality of application properties corresponding to the plurality of application scopes, the one or more application properties including a functional attribute related to a function of the specific computing application, obtaining a piece of threat intelligence data from a data source; mapping the piece of threat intelligence data to the plurality of application scopes; determining to which of the one or more security gateway systems to send the piece of threat intelligence data based on the security policy; transmitting the piece of threat intelligence data to at least one of the one or more security gateway systems based on the determining.",computerimplemented method managing security service one cloud computing platform disclosed method comprises receiving main controller security policy client device client device associated set computing application hosted one independent private virtual cluster one cloud computing platform main controller residing outside one virtual cluster one virtual cluster served security gateway system residing within one cloud computing platform security policy indicating threat intelligence data applied set computing application respect plurality application scope receiving application data client device application data indicating whether specific computing application set computing application one application property plurality application property plurality application property corresponding plurality application scope one application property including functional attribute related function specific computing application obtaining piece threat intelligence data data source mapping piece threat intelligence data plurality application scope determining one security gateway system send piece threat intelligence data based security policy transmitting piece threat intelligence data least one one security gateway system based determining,2
"The invention relates to an API-based anti-harassment outbound method. The anti-harassment outbound method comprises the following steps that S1, an AI outbound unit initiates an outbound request to a line provider unit through a sip protocol; S2, after receiving the request, the line provider unit calls an anti-harassment outbound API stored in an outbound API unit for detection; and S3, if detection is passed, an outbound signaling is forwarded to continue to call the called party, if the detection is not passed, the call is ended, and a call failure and blacklist state code are returned to the calling party. According to the technical scheme provided by the invention, before a line manufacturer receives the call signaling and forwards the call signaling, the anti-harassment detection API is called firstly, if the detection is not passed, the call is directly terminated, and the blacklist state code is returned to the calling party, so that line resources of the line manufacturer can be prevented from being complained, marked and blacklisted through detection, and the call completing rate is improved.",invention relates apibased antiharassment outbound method antiharassment outbound method comprises following step outbound unit initiate outbound request line provider unit sip protocol receiving request line provider unit call antiharassment outbound api stored outbound api unit detection detection passed outbound signaling forwarded continue call called party detection passed call ended call failure blacklist state code returned calling party according technical scheme provided invention line manufacturer receives call signaling forward call signaling antiharassment detection api called firstly detection passed call directly terminated blacklist state code returned calling party line resource line manufacturer prevented complained marked blacklisted detection call completing rate improved,-1
"A method for detecting abuse of zero-rated data includes monitoring usage patterns of a group of users for a particular data type, including zero-rated data usage by the group of users and setting a zero-rated data-usage threshold for the particular data type based at least in part on the monitored usage. The method also includes continuing to monitor the usage patterns of the group of users for the particular data type during a period of time, including the zero-rated data usage of the group of users. The method further includes determining whether a zero-rated data usage for the particular data type by a user in the group during the period of time satisfies the zero-rated threshold, and in response to determining that the zero-rated data usage by the user during the period of time satisfies the zero-rated threshold, flagging an account associated with the user as a potential abuser.",method detecting abuse zerorated data includes monitoring usage pattern group user particular data type including zerorated data usage group user setting zerorated datausage threshold particular data type based least part monitored usage method also includes continuing monitor usage pattern group user particular data type period time including zerorated data usage group user method includes determining whether zerorated data usage particular data type user group period time satisfies zerorated threshold response determining zerorated data usage user period time satisfies zerorated threshold flagging account associated user potential abuser,1
"A server-implemented technique can include obtaining external context parameters indicative of an external context of a video chat session, calculating an abuse score based on the external context parameters, the abuse score being indicative of a likelihood the video chat session is abusive, and comparing the abuse score to an abuse score threshold. When the abuse score exceeds an abuse score threshold, the server can transmit, to a reviewer computing device, a request for a human reviewer to review a recorded portion of the video chat session for abuse. When the reviewer computing device returns a response indicating that the human reviewer deemed the video chat session to be abusive, the server can modify a profile of a participant in the abusive video chat session to obtain a modified profile, and generate an output based on the modified profile.",serverimplemented technique include obtaining external context parameter indicative external context video chat session calculating abuse score based external context parameter abuse score indicative likelihood video chat session abusive comparing abuse score abuse score threshold abuse score exceeds abuse score threshold server transmit reviewer computing device request human reviewer review recorded portion video chat session abuse reviewer computing device return response indicating human reviewer deemed video chat session abusive server modify profile participant abusive video chat session obtain modified profile generate output based modified profile,-1
"The utility model relates to the technical field of radiation harassment detection, and discloses a transportable radiation harassment authentication testing device, which comprises a placement box and a tester, the tester is placed on the inner side of the placement box, and an adjusting mechanism is arranged below the placement box; the adjusting mechanism comprises a fixed block, a sliding piece, a corner piece, a threaded rod, a supporting column and a supporting plate. And fixing blocks are fixedly mounted at the four corners of the lower portion of the containing box correspondingly. According to the transportable radiation disturbance authentication testing device, a tester is moved to a designated position, then a clamping table is rotated, so that a supporting column can be supported, after completion, an operator pulls a connecting plate outwards, so that a sliding block slides on the inner side of a sliding groove, and after the connecting plate slides to the designated position, the supporting column is rotated, so that the supporting column is supported; therefore, the supporting column can rotate downwards on the outer side of the threaded rod, the height of the upper placing box can be adjusted, and the whole testing device can be conveniently placed.",utility model relates technical field radiation harassment detection discloses transportable radiation harassment authentication testing device comprises placement box tester tester placed inner side placement box adjusting mechanism arranged placement box adjusting mechanism comprises fixed block sliding piece corner piece threaded rod supporting column supporting plate fixing block fixedly mounted four corner lower portion containing box correspondingly according transportable radiation disturbance authentication testing device tester moved designated position clamping table rotated supporting column supported completion operator pull connecting plate outwards sliding block slide inner side sliding groove connecting plate slide designated position supporting column rotated supporting column supported therefore supporting column rotate downwards outer side threaded rod height upper placing box adjusted whole testing device conveniently placed,-1
"Provided is an autonomous deep learning-based abuse detection system using surveillance camera images, which includes: a clip generation unit which generates a video clip by considering the preset number of frames, the preset frame interval, and the preset frame start interval in a photographed image; a violence detection unit which detects violence in the video clip using a preset deep learning model; a face detection unit which detects a face image from the video clip in which violence is detected; and a mosaic generation unit which performs mosaic image processing on the face image detected in the face detection unit.",provided autonomous deep learningbased abuse detection system using surveillance camera image includes clip generation unit generates video clip considering preset number frame preset frame interval preset frame start interval photographed image violence detection unit detects violence video clip using preset deep learning model face detection unit detects face image video clip violence detected mosaic generation unit performs mosaic image processing face image detected face detection unit,-1
"The subject of the invention is the recognition of a user's emotional state and supporting their mood, particularly when experiencing loneliness. A specific goal is to help the user obtain sufficient interaction with relatives and friends when their mood is slipping into a concerning area. The objective is also that the connection is automatically opened to exactly the right person who can best help the user return to a safe and healthy mood and mental state. As an alternative to making contact, for example, when a suitable contact person is not reachable, providing the user with music, games, podcasts, videos, or other mood interventions appropriate to the emotional state is also targeted. These objectives are achieved through a system built into a smartwatch (101) and smartphone (121) that measures, recognizes, and monitors the user's vitality (107) and emotional state (127) throughout the day, and opens a communication link (140) or a mood intervention suitable for the situation when set conditions are met.",subject invention recognition user emotional state supporting mood particularly experiencing loneliness specific goal help user obtain sufficient interaction relative friend mood slipping concerning area objective also connection automatically opened exactly right person best help user return safe healthy mood mental state alternative making contact example suitable contact person reachable providing user music game podcasts video mood intervention appropriate emotional state also targeted objective achieved system built smartwatch smartphone measure recognizes monitor user vitality emotional state throughout day open communication link mood intervention suitable situation set condition met,-1
"The interactive learning system comprises the following interconnected modules: 1. ""Load distribution"" 2. Network Security 3. ""Server"" 4. ""User interface"" 5. ""Server applications"" 6. ""Artificial Intelligence"" 7. ""Machine learning"" 8. Format Conversion The communication part of the system is designed via the client-server model, and the latter is upgraded with various algorithms and capabilities in order to optimize and improve the connection, which in turn facilitates the learning process. The teacher creates a virtual classroom and allows a certain number of students to the class session. Everyone (both teacher and students) sees on their screen a virtual ""whiteboard"" which occupies most of the screen. You can write, draw, start presentations, video and audio clips or pre-designed lessons on the board. These functionalities can be indefinitely extended and upgraded. The developed ""Whiteboard"", which is the central part of the learning process, is specially created in a way that resembles the interface of popular drawing applications in order to look and function in a way familiar to students. The specially developed algorithms with the use of Artificial Intelligence and Machine Learning monitor both the learning process and the self-preparation of students, as based on the submitted tests create a personal profile of each learner. Aggregated reports on different characteristics of a student, group of students, subjects and topics are also created. The reports and profiles are available to teachers and management bodies so that they can quickly track the processes and results. The system has the ability to warn of various events (e.g .poor results of a student, class, teacher, the so-called ""hate speech"" and so forth. The system has developed options for a chat, audio connection, file exchange, ""drawing"" on the virtual board by students, etc., however only upon authorization by the teacher.",interactive learning system comprises following interconnected module load distribution network security server user interface server application artificial intelligence machine learning format conversion communication part system designed via clientserver model latter upgraded various algorithm capability order optimize improve connection turn facilitates learning process teacher creates virtual classroom allows certain number student class session everyone teacher student see screen virtual whiteboard occupies screen write draw start presentation video audio clip predesigned lesson board functionality indefinitely extended upgraded developed whiteboard central part learning process specially created way resembles interface popular drawing application order look function way familiar student specially developed algorithm use artificial intelligence machine learning monitor learning process selfpreparation student based submitted test create personal profile learner aggregated report different characteristic student group student subject topic also created report profile available teacher management body quickly track process result system ability warn various event poor result student class teacher socalled hate speech forth system developed option chat audio connection file exchange drawing virtual board student etc however upon authorization teacher,-1
"A pedestrian terminal transmits a message including pedestrian information to a roadside machine. In a case where the message transmitted from the pedestrian terminal is received, the roadside machine accumulates the pedestrian information included in the message as passage history information, detects occurrence of an abnormal event for a person possessing the pedestrian terminal based on the passage history information, and transmits the message including information indicating that the abnormal event occurs for the person possessing the pedestrian terminal to a nearby pedestrian terminal.",pedestrian terminal transmits message including pedestrian information roadside machine case message transmitted pedestrian terminal received roadside machine accumulates pedestrian information included message passage history information detects occurrence abnormal event person possessing pedestrian terminal based passage history information transmits message including information indicating abnormal event occurs person possessing pedestrian terminal nearby pedestrian terminal,-1
"The invention provides a method and system for protecting virtual machine safety under virtual platform network isolation. The method comprises the steps: obtaining an online threat information list,and forming a threat information library; after receiving a process collection instruction issued by the QGA monitoring module, the virtual machine collects current running process information of thevirtual machine through the qemu-ga module to form a process list, calculates a hash value of each process file in the process list, and returns the hash value to the QGA monitoring module; checking whether the hash value exists in the threat intelligence library or not, If yes, adding the process information into a virtual machine vulnerability information table; and the safety management centergives an alarm prompt according to the virtual machine vulnerability information table. Under the condition of network isolation, the data interaction between the virtualization management platform and the virtual machine is formed through the QGA monitoring module and the qemu-ga module, the safety management of the virtualization management platform on the virtual machine is realized, and the information safety of the virtual machine is ensured.",invention provides method system protecting virtual machine safety virtual platform network isolation method comprises step obtaining online threat information listand forming threat information library receiving process collection instruction issued qga monitoring module virtual machine collect current running process information thevirtual machine qemuga module form process list calculates hash value process file process list return hash value qga monitoring module checking whether hash value exists threat intelligence library yes adding process information virtual machine vulnerability information table safety management centergives alarm prompt according virtual machine vulnerability information table condition network isolation data interaction virtualization management platform virtual machine formed qga monitoring module qemuga module safety management virtualization management platform virtual machine realized information safety virtual machine ensured,2
A treatment service mediation server includes a metaverse space providing unit configured to provide a metaverse space for the cognitive and social treatment service to a device of the child with developmental disabilities and a device of a therapist; a data collection unit configured to collect life-logging data including user data and cognitive and social response data of the child with developmental disabilities; a mental state estimation unit configured to estimate a mental state of the child with developmental disabilities from the life-logging data through an artificial intelligence model; a treatment service providing unit configured to provide the cognitive and social treatment service of the child with developmental disabilities to the device of the child with developmental disabilities based on the estimated mental state of the child with developmental disabilities; and a treatment result providing unit configured to provide a treatment result report on the cognitive and social treatment service.,treatment service mediation server includes metaverse space providing unit configured provide metaverse space cognitive social treatment service device child developmental disability device therapist data collection unit configured collect lifelogging data including user data cognitive social response data child developmental disability mental state estimation unit configured estimate mental state child developmental disability lifelogging data artificial intelligence model treatment service providing unit configured provide cognitive social treatment service child developmental disability device child developmental disability based estimated mental state child developmental disability treatment result providing unit configured provide treatment result report cognitive social treatment service,-1
"The disclosure provides methods and systems for interactive video content delivery. An example method comprises receiving a video content such as live television or video streaming. The method can run one or more machine-learning classifiers on video frames of the video content to create classification metadata corresponding to the machine-learning classifiers and one or more probability scores associated with the classification metadata. Furthermore, the method can create one or more interaction triggers based on a set of predetermined rules and optionally user profiles. The method can determine that a condition for triggering at least one of the triggers is met and triggers at least one of the actions with regard to the video content based on the determination, the classification metadata, and the probability scores. For example, the action can deliver additional information, present recommendations, automatically edit the video content, or control delivery of video content.",disclosure provides method system interactive video content delivery example method comprises receiving video content live television video streaming method run one machinelearning classifier video frame video content create classification metadata corresponding machinelearning classifier one probability score associated classification metadata furthermore method create one interaction trigger based set predetermined rule optionally user profile method determine condition triggering least one trigger met trigger least one action regard video content based determination classification metadata probability score example action deliver additional information present recommendation automatically edit video content control delivery video content,0
"A processor of a detection server coupled to a telephony network may be configured to detect a call event that is currently ongoing. The processor may be configured to analyze call data associated with the call event to determine that a call triggering the call event will cause an inefficiency on the telephony network in response to standard handling of the call by the telephony network. The processor may be configured to cause the telephony network to handle the call in a non-standard manner, thereby preventing the inefficiency.",processor detection server coupled telephony network may configured detect call event currently ongoing processor may configured analyze call data associated call event determine call triggering call event cause inefficiency telephony network response standard handling call telephony network processor may configured cause telephony network handle call nonstandard manner thereby preventing inefficiency,-1
"Various embodiments described in the invention relate to equipment abuse detection using machine learning. In this aspect, the system compares accelerometer data of electronic equipment to a plurality of defined accelerometer thresholds to identify a primary abuse event category associated with the electronic equipment. In response to identifying the primary abuse event category, the system generates a first prediction for a secondary abuse event category associated with the electronic equipment based on machine learning techniques associated with inertial data of the electronic equipment, image data generated by the electronic equipment, and audio data captured by the electronic equipment. Furthermore, the system transmits the inertial data, the image data, and the audio data to web server equipment associated with the machine learning service to facilitate generation of a second prediction for the secondary abuse event category based on the inertial data, the image data, and the audio data.",various embodiment described invention relate equipment abuse detection using machine learning aspect system compare accelerometer data electronic equipment plurality defined accelerometer threshold identify primary abuse event category associated electronic equipment response identifying primary abuse event category system generates first prediction secondary abuse event category associated electronic equipment based machine learning technique associated inertial data electronic equipment image data generated electronic equipment audio data captured electronic equipment furthermore system transmits inertial data image data audio data web server equipment associated machine learning service facilitate generation second prediction secondary abuse event category based inertial data image data audio data,1
"A wearable physiological monitoring system comprises commercially available off-the shelf components. With the growth of interrelated systems of computing devices, mechanical and digital machines, objects, animals or people connected by the Internet, there is a significant interest in the use of wearable sensors such as cell watches, and cell phones. These wearable sensors may be used to monitor physiological signals and provide health information. An edge-intelligent Internet based wearable assists in substance-abuse detection by monitoring and interpreting an individual's physiological signals on continuous basis. The wearable device helps in monitoring cravings and substance abuse of the individual and help the healthcare provider to start an early intervention as required. The proposed system is developed as a dedicated substance abuse wearable system. An example of a wearable device is a medical quality wearable which yielded a correlation of 0.89 for accelerometer measurements and 0.92 for average heart rate measurements in tests.",wearable physiological monitoring system comprises commercially available offthe shelf component growth interrelated system computing device mechanical digital machine object animal people connected internet significant interest use wearable sensor cell watch cell phone wearable sensor may used monitor physiological signal provide health information edgeintelligent internet based wearable assist substanceabuse detection monitoring interpreting individual physiological signal continuous basis wearable device help monitoring craving substance abuse individual help healthcare provider start early intervention required proposed system developed dedicated substance abuse wearable system example wearable device medical quality wearable yielded correlation accelerometer measurement average heart rate measurement test,-1
"Presented are a method, system, and apparatus for determining whether an electronically submitted medical claim has a high likelihood of being fraud, waste, and/or abuse in medical billing. A computing device receives the electronic medical claim containing a subject patient identifier identifying a subject patient. A plurality of subject patient characteristic datapoints are accessed with the subject patient identifier and the datapoints segmented. Event codes regarding each patient are accessed to generate one or more event sequences. The event sequences are grouped according to a particular event followed by one or more related events and analyzed to calculate a probability the related events following the particular event. The event sequences are analyzed again and a probability calculated of the particular event following the related events. Other steps may be utilized, and the submitted medical claim dishonored if it has a high likelihood of being fraud, waste, and/or abuse.",presented method system apparatus determining whether electronically submitted medical claim high likelihood fraud waste andor abuse medical billing computing device receives electronic medical claim containing subject patient identifier identifying subject patient plurality subject patient characteristic datapoints accessed subject patient identifier datapoints segmented event code regarding patient accessed generate one event sequence event sequence grouped according particular event followed one related event analyzed calculate probability related event following particular event event sequence analyzed probability calculated particular event following related event step may utilized submitted medical claim dishonored high likelihood fraud waste andor abuse,2
"A wearable physiological monitoring system comprises commercially available off-the shelf components. With the growth of interrelated systems of computing devices, mechanical and digital machines, objects, animals or people connected by the Internet, there is a significant interest in the use of wearable sensors such as cell watches, and smart phones. These wearable sensors may be used to monitor physiological signals and provide health information. An edge-intelligent Internet based wearable assists in substance-abuse detection by monitoring and interpreting an individual's physiological signals on continuous basis. The wearable device helps in monitoring cravings and substance abuse of the individual and help the healthcare provider to start an early intervention as required. The proposed system is developed as a dedicated substance abuse wearable system. An example of a wearable device is a medical quality wearable which yielded a correlation of 0.89 for accelerometer measurements and 0.92 for average heart rate measurements in tests.",wearable physiological monitoring system comprises commercially available offthe shelf component growth interrelated system computing device mechanical digital machine object animal people connected internet significant interest use wearable sensor cell watch smart phone wearable sensor may used monitor physiological signal provide health information edgeintelligent internet based wearable assist substanceabuse detection monitoring interpreting individual physiological signal continuous basis wearable device help monitoring craving substance abuse individual help healthcare provider start early intervention required proposed system developed dedicated substance abuse wearable system example wearable device medical quality wearable yielded correlation accelerometer measurement average heart rate measurement test,1
"The invention discloses an ultra-short wave threat signal sensing method based on support vector data description. The method mainly comprises a signal acquisition module, a time-frequency analysis module, a data dimension reduction module, a support vector data description model training module, an online threat sensing module and the like. The method mainly comprises the following steps: acquiring our signals in a space by using a radio frequency board card; performing time-frequency analysis on the baseband complex signal according to a short-time Fourier transform theory to generate a time-frequency spectrogram, and constructing a our signal time-frequency spectrogram database; converting the time-frequency spectrogram into a low-dimensional feature vector according to an image preprocessing technology and a principal component analysis theory; and training a support vector data description model to construct a minimum hypersphere capable of including all target samples, determining our signal by the samples falling into the hypersphere, and determining the samples located outside the hypersphere as potential threat signals. According to the method, the support vector data description model of the non-threat signals is constructed only by utilizing a signal database of our party, so that the problem of opening sets of the threat signals is effectively solved.",invention discloses ultrashort wave threat signal sensing method based support vector data description method mainly comprises signal acquisition module timefrequency analysis module data dimension reduction module support vector data description model training module online threat sensing module like method mainly comprises following step acquiring signal space using radio frequency board card performing timefrequency analysis baseband complex signal according shorttime fourier transform theory generate timefrequency spectrogram constructing signal timefrequency spectrogram database converting timefrequency spectrogram lowdimensional feature vector according image preprocessing technology principal component analysis theory training support vector data description model construct minimum hypersphere capable including target sample determining signal sample falling hypersphere determining sample located outside hypersphere potential threat signal according method support vector data description model nonthreat signal constructed utilizing signal database party problem opening set threat signal effectively solved,-1
"A system (10) for input risk identification within an artificial intelligence responsible governance platform is disclosed The system includes a processing subsystem (50) hosted on a server (60), the system enables bidirectional communications among multiple modules. The core component, a neural network with attention based AI risk classification module (70), employs various submodules including privacy, financial, health, intellectual property, technology, and confidential information, each meticulously trained and configured. Leveraging advanced machine learning techniques, such as natural language processing, pattern recognition, and contextual analysis, these submodules identify and categorize risks within user input or information flows. The annotation module (140) ensures clarity by annotating identified risks, while the feedback module (150) collects user insights for continuous improvement. The output module (160) communicates risk classification data to downstream risk mitigation modules, offering a comprehensive solution for managing and mitigating diverse risks associated with artificial intelligence interactions in accordance with organizational policies and regulatory requirements.",system input risk identification within artificial intelligence responsible governance platform disclosed system includes processing subsystem hosted server system enables bidirectional communication among multiple module core component neural network attention based risk classification module employ various submodules including privacy financial health intellectual property technology confidential information meticulously trained configured leveraging advanced machine learning technique natural language processing pattern recognition contextual analysis submodules identify categorize risk within user input information flow annotation module ensures clarity annotating identified risk feedback module collect user insight continuous improvement output module communicates risk classification data downstream risk mitigation module offering comprehensive solution managing mitigating diverse risk associated artificial intelligence interaction accordance organizational policy regulatory requirement,2
Techniques for presenting information indicating infrastructure security and compliance of services of a customer cloud environment to a customer-facing dashboard are disclosed. The information presented to the customer-facing dashboard is a subset of information available to operators associated with a cloud service provider (CSP). A tier-one dashboard service obtains information indicating infrastructure security and compliance of services in the customer cloud infrastructure environment. The tier-one dashboard service presents the information indicating infrastructure security and compliance to CSP operators on a CSP-facing dashboard. The CSP-facing dashboard is not accessible by customer operators. A tier-two dashboard service obtains the infrastructure security and compliance information from the tier-one dashboard service and filters the infrastructure security information to create a subset of information indicating the security and compliance of the services. The subset of infrastructure security and compliance information is presented to operators associated with a customer of the CSP on a customer-facing dashboard.,technique presenting information indicating infrastructure security compliance service customer cloud environment customerfacing dashboard disclosed information presented customerfacing dashboard subset information available operator associated cloud service provider csp tierone dashboard service obtains information indicating infrastructure security compliance service customer cloud infrastructure environment tierone dashboard service present information indicating infrastructure security compliance csp operator cspfacing dashboard cspfacing dashboard accessible customer operator tiertwo dashboard service obtains infrastructure security compliance information tierone dashboard service filter infrastructure security information create subset information indicating security compliance service subset infrastructure security compliance information presented operator associated customer csp customerfacing dashboard,2
"The invention discloses a Servlet interceptor-based security protection method, which is characterized by comprising the following steps of: constructing an interceptor; the configuration server side obtains an object accessing the context information; accumulatively calculating and comparing abuse detection index items; generating a decryption key based on the user name and the access time and returning the decryption key to the browser side; comparing the unforbidden key input by the user with the unforbidden key in the interceptor; intercepting and acquiring different types of request data by each interceptor, and executing blacklist and whitelist verification; and calling a component of an attack detection method preset in the interceptor, and detecting whether attack data exists in the user input data and the system output data. The effects of identifying different levels of security problems, executing different degrees of monitoring processing, realizing graded prevention and control, reducing manual monitoring and processing of vulnerability problems, and more importantly, improving the coverage of security prevention and control, and finally improving the prevention and control efficiency are achieved.",invention discloses servlet interceptorbased security protection method characterized comprising following step constructing interceptor configuration server side obtains object accessing context information accumulatively calculating comparing abuse detection index item generating decryption key based user name access time returning decryption key browser side comparing unforbidden key input user unforbidden key interceptor intercepting acquiring different type request data interceptor executing blacklist whitelist verification calling component attack detection method preset interceptor detecting whether attack data exists user input data system output data effect identifying different level security problem executing different degree monitoring processing realizing graded prevention control reducing manual monitoring processing vulnerability problem importantly improving coverage security prevention control finally improving prevention control efficiency achieved,2
"The present invention relates to a device and method for detecting an abuser of an advertisement compensating system and a recording medium for performing the same. More specifically, the device and method detect a computer terminal (hereinafter referred to as Abuser) disguised as a mobile terminal by an emulator by utilizing a motion sensor configured only in a mobile terminal and prevent fraudulent accumulation of reward according to use of advertisement service through a mobile application installed on the emulator. The device comprises: a communication unit; and a server control unit.",present invention relates device method detecting abuser advertisement compensating system recording medium performing specifically device method detect computer terminal hereinafter referred abuser disguised mobile terminal emulator utilizing motion sensor configured mobile terminal prevent fraudulent accumulation reward according use advertisement service mobile application installed emulator device comprises communication unit server control unit,1
"In an embodiment, a computer-implemented method detects a network or application abuse to a service provider environment. In the method, data is collected describing incoming requests from plurality of different external source addresses to the service provider environment. The collected data is used to compare the incoming requests against a heuristic. When the incoming requests are determined to match the heuristic, the requests, having the plurality of different external source addresses, are from a common abuse entity. Finally, the collected data is evaluated to determine that the common abuse entity is a potential network abuser of the service provider environment.",embodiment computerimplemented method detects network application abuse service provider environment method data collected describing incoming request plurality different external source address service provider environment collected data used compare incoming request heuristic incoming request determined match heuristic request plurality different external source address common abuse entity finally collected data evaluated determine common abuse entity potential network abuser service provider environment,1
"A vehicle interior occupant protection system includes a table disposed in a vehicle interior cabin; the at least two seats are arranged in the circumferential direction of the table; the safety air bag assemblies are arranged in one-to-one correspondence with the seats and comprise inner-layer air bags, outer-layer air bags and connecting pieces, the inner-layer air bags are connected to the table and can inflate the seats from the table, at least part of the inner-layer air bags extend towards the adjacent seats when the inner-layer air bags are inflated, and the outer-layer air bags are connected to the outer sides of the inner-layer air bags through the connecting pieces; the outer-layer air bag can be inflated to the seat from the connecting piece, in actual use, the outer-layer air bag is inflated to the direction of the seat, protection of the air bags is targeted, abuse of air bag protection is avoided, whether the inner-layer air bag is inflated or not can be selected according to the collision condition, only one air bag can be independently replaced in subsequent replacement, and the cost is reduced. And the use and replacement cost of the air bag is effectively reduced.",vehicle interior occupant protection system includes table disposed vehicle interior cabin least two seat arranged circumferential direction table safety air bag assembly arranged onetoone correspondence seat comprise innerlayer air bag outerlayer air bag connecting piece innerlayer air bag connected table inflate seat table least part innerlayer air bag extend towards adjacent seat innerlayer air bag inflated outerlayer air bag connected outer side innerlayer air bag connecting piece outerlayer air bag inflated seat connecting piece actual use outerlayer air bag inflated direction seat protection air bag targeted abuse air bag protection avoided whether innerlayer air bag inflated selected according collision condition one air bag independently replaced subsequent replacement cost reduced use replacement cost air bag effectively reduced,-1
"The present invention relates to a motor vehicle driving qualification verification system and method and belongs to the traffic technology field. The system includes a first fingerprint acquisition unit disposed outside a vehicle, a second fingerprint acquisition unit disposed in the vehicle, an image acquisition unit, an alcohol abuse detection unit, a vehicle-mounted computer, an alarm unit, auser identity authentication unit and an Internet big data center. With the motor vehicle driving qualification verification system and method of the invention adopted, in the driving process of a motor vehicle, the validity of a motor vehicle driving permit and a motor vehicle driving license can be continuously verified; the physical and mental state of the body of a driver can be continuously verified; an existing motor vehicle key can be replaced, so that problems caused by a condition that the key is forged, lost, forgotten, robbed or the like can be avoided; a more convenient and safer motor vehicle use method can be provided; the enforcement of traffic laws and regulations can be enhanced; illegal driving of motor vehicles can be effectively prevented; the qualification examinationproblem of the renters of shared vehicles can be solved; the promotion and popularization of the shared vehicles can be benefitted; and the risk of the robbery of the motor vehicles can be reduced.",present invention relates motor vehicle driving qualification verification system method belongs traffic technology field system includes first fingerprint acquisition unit disposed outside vehicle second fingerprint acquisition unit disposed vehicle image acquisition unit alcohol abuse detection unit vehiclemounted computer alarm unit auser identity authentication unit internet big data center motor vehicle driving qualification verification system method invention adopted driving process motor vehicle validity motor vehicle driving permit motor vehicle driving license continuously verified physical mental state body driver continuously verified existing motor vehicle key replaced problem caused condition key forged lost forgotten robbed like avoided convenient safer motor vehicle use method provided enforcement traffic law regulation enhanced illegal driving motor vehicle effectively prevented qualification examinationproblem renter shared vehicle solved promotion popularization shared vehicle benefitted risk robbery motor vehicle reduced,-1
"A computer readable medium comprising software instructions for purchasing units, wherein the software instructions, when executed by a processor, enable a system including the processor to receive a request for an initial trial unit from a user, receive a request to purchase the initial trial unit from the user, complete the purchase of the initial trial unit using a first financial incentive, wherein the purchase of the initial trial unit is completed within an initial unit conversion period, provide, to the user, a second financial incentive to purchase at least one conversion unit after the completion of the purchase of the first unit, receive a request to purchase the at least one conversion unit, and complete the purchase of the at least one conversion unit using the second financial incentive, wherein the purchase of the second conversion unit is completed within a total promotion period.",computer readable medium comprising software instruction purchasing unit wherein software instruction executed processor enable system including processor receive request initial trial unit user receive request purchase initial trial unit user complete purchase initial trial unit using first financial incentive wherein purchase initial trial unit completed within initial unit conversion period provide user second financial incentive purchase least one conversion unit completion purchase first unit receive request purchase least one conversion unit complete purchase least one conversion unit using second financial incentive wherein purchase second conversion unit completed within total promotion period,0
"Current technology cannot represent the combined variable values into one meaningful value that reflects the overall risk that this observation is an outlier. The single value, the score, must be capable of being measured on the same scale across different segments, such as geographies and specialty groups. Lastly, the score must substantially, monotonically rank the fraud risk and give reasons to substantiate the score.",current technology represent combined variable value one meaningful value reflects overall risk observation outlier single value score must capable measured scale across different segment geography specialty group lastly score must substantially monotonically rank fraud risk give reason substantiate score,-1
Techniques for presenting information indicating infrastructure security and compliance of services of a customer cloud environment to a customer-facing dashboard are disclosed. The information presented to the customer-facing dashboard is a subset of information available to operators associated with a cloud service provider (CSP). A tier-one dashboard service obtains information indicating infrastructure security and compliance of services in the customer cloud infrastructure environment. The tier-one dashboard service presents the information indicating infrastructure security and compliance to CSP operators on a CSP-facing dashboard. The CSP-facing dashboard is not accessible by customer operators. A tier-two dashboard service obtains the infrastructure security and compliance information from the tier-one dashboard service and filters the infrastructure security information to create a subset of information indicating the security and compliance of the services. The subset of infrastructure security and compliance information is presented to operators associated with a customer of the CSP on a customer-facing dashboard.,technique presenting information indicating infrastructure security compliance service customer cloud environment customerfacing dashboard disclosed information presented customerfacing dashboard subset information available operator associated cloud service provider csp tierone dashboard service obtains information indicating infrastructure security compliance service customer cloud infrastructure environment tierone dashboard service present information indicating infrastructure security compliance csp operator cspfacing dashboard cspfacing dashboard accessible customer operator tiertwo dashboard service obtains infrastructure security compliance information tierone dashboard service filter infrastructure security information create subset information indicating security compliance service subset infrastructure security compliance information presented operator associated customer csp customerfacing dashboard,2
"A system and method for generating an insult rate and reconfiguring an automated decisioning workflow includes configuring a testing group based on sampling from online events having an adverse disposal decision computed by an automated decisioning workflow computer that is configured with machine learning-based threat score thresholds that, if satisfied, causes a computation of a disallow decision or a block decision for a given online event; evaluating a performance and collecting performance data of distinct members of the testing group over a testing period; computing an insult rate for the testing group based on the performance data; computing an insult rate equilibrium for the automated decisioning workflow computer based on the performance data; evaluating the insult rate against the insult rate equilibrium; and reconfiguring adverse decisioning thresholds based on the evaluation of the insult rate of the testing group against the insult rate equilibrium for the automated decisioning workflow computer.",system method generating insult rate reconfiguring automated decisioning workflow includes configuring testing group based sampling online event adverse disposal decision computed automated decisioning workflow computer configured machine learningbased threat score threshold satisfied cause computation disallow decision block decision given online event evaluating performance collecting performance data distinct member testing group testing period computing insult rate testing group based performance data computing insult rate equilibrium automated decisioning workflow computer based performance data evaluating insult rate insult rate equilibrium reconfiguring adverse decisioning threshold based evaluation insult rate testing group insult rate equilibrium automated decisioning workflow computer,-1
"The present invention relates to an access management apparatus for managing database access based on a web application server and a method thereof. More specifically, the present invention relates to the access management apparatus for managing database access based on a web application server and the method thereof, which prevent performance degradation of a web application server by automatically mapping a relation between a uniform resource locator (URL) request and a structured query language (SQL) request transmitted based on the URL request by the web application server receiving the URL request through session connection with a user terminal, without using a resource of the web application server. The access management apparatus for managing database access based on a web application server obtains the URL request and the SQL request through sniffing without the need to insert an agent program for information collection into the web application server. The access management apparatus for managing database access based on a web application server can also easily identify an SQL executed by an application user by connecting the relation between the SQL request and the URL request obtained through an intuitive mapping algorithm. Accordingly, the access management apparatus for managing database access based on a web application server supports performance analysis of an application module and a security function, such as abuse detection to execute the performance analysis of the application module and the security function without inserting the agent program for information collection into the web application server. Therefore, the access management apparatus for managing database access based on a web application server can fundamentally block the generation of an existing fatal problem, such as performance degradation and a failure of the web application server caused by excessive resource use of the web application server by the agent program for information collection. Moreover, the access management apparatus for managing database access based on a web application server can contribute to an increase of the resource availability of the web application server.",present invention relates access management apparatus managing database access based web application server method thereof specifically present invention relates access management apparatus managing database access based web application server method thereof prevent performance degradation web application server automatically mapping relation uniform resource locator url request structured query language sql request transmitted based url request web application server receiving url request session connection user terminal without using resource web application server access management apparatus managing database access based web application server obtains url request sql request sniffing without need insert agent program information collection web application server access management apparatus managing database access based web application server also easily identify sql executed application user connecting relation sql request url request obtained intuitive mapping algorithm accordingly access management apparatus managing database access based web application server support performance analysis application module security function abuse detection execute performance analysis application module security function without inserting agent program information collection web application server therefore access management apparatus managing database access based web application server fundamentally block generation existing fatal problem performance degradation failure web application server caused excessive resource use web application server agent program information collection moreover access management apparatus managing database access based web application server contribute increase resource availability web application server,2
"An installation is provided for multi-dimensional non-linear imaging of a material comprising intrinsic chromophores, using laser scanning. This installation comprises i) at least one source (115) of time stamp pulses of synchronized photons, ii) means (12-14) for locally focusing the pulses on a material to cause its intrinsic chromophores to absorb groups of at least two synchronized photons to produce response photons, iii) means (22,40,53) for directing the response photons to at least one collecting zone, iv) means (30-34) for collecting the response photons in the collecting zone(s), whatever their energy, v) processing means for converting the collected photons into data at least representative of their number and storing them in correspondence with at least the time stamp pulses that cause the material to produce the response photons, vi) means for scanning (11,20) the pulses through a chosen area of the material, and vii) means for delivering from said data stored an image representative of said material chosen area, with a sub-millimeter resolution, and in function of the respective time stamp pulses of data. <IMAGE>",installation provided multidimensional nonlinear imaging material comprising intrinsic chromophore using laser scanning installation comprises least one source time stamp pulse synchronized photon mean locally focusing pulse material cause intrinsic chromophore absorb group least two synchronized photon produce response photon iii mean directing response photon least one collecting zone mean collecting response photon collecting zone whatever energy processing mean converting collected photon data least representative number storing correspondence least time stamp pulse cause material produce response photon mean scanning pulse chosen area material vii mean delivering said data stored image representative said material chosen area submillimeter resolution function respective time stamp pulse data image,1
"DEFAMATION 2GO Abstract: A direct on-line website designed portal and App, designed to enable people to access cost effective legal assistance to deal with cyber-bullying, harassment and defamation through social media. The ability to have legal issues dealt with at the click of a button through the APP and Portal in a professional and legal way to bring about a timely and effective resolution to the problems involved in the use of modern technology involving the internet and social media in all aspects.",defamation abstract direct online website designed portal app designed enable people access cost effective legal assistance deal cyberbullying harassment defamation social medium ability legal issue dealt click button app portal professional legal way bring timely effective resolution problem involved use modern technology involving internet social medium aspect,0
Disclosed herein are systems and methods digital asset management using perfect secrecy encryption and transcryption technology. This can be used for signature/approval as well as digital ledgers without the need for a blockchain for generic assets. Digital assets and the associated meta data can be combined into a single digital bundle protected in perfect secrecy. The technology can be deployed in two different methods depending on the desired application; mutable and immutable.,disclosed herein system method digital asset management using perfect secrecy encryption transcryption technology used signatureapproval well digital ledger without need blockchain generic asset digital asset associated meta data combined single digital bundle protected perfect secrecy technology deployed two different method depending desired application mutable immutable,-1
"An aircraft window shade includes protective transparent window panels, a shade driven by an electric motor, an integral control panel, and support for remote operation. The shade uses dual sprocket drive for positive shade positioning, low wear, and low parts count. The moving shade element remains substantially flat, curving slightly during some phases of positioning. The apparatus replaces a conventional interior window panel and a manual shade with slight change in overall mechanism thickness and weight. Control electronics in the shade can accept a command from a cabin attendant's console to override the local setting and move the shade to a required position, such as fully open for takeoff. The shade supports use of two or more independent shades, each of which can be made of dimming (transparent), diffusing (translucent), or light blocking (opaque) material. The shade is compatible with electrochromic transmittance control technology.",aircraft window shade includes protective transparent window panel shade driven electric motor integral control panel support remote operation shade us dual sprocket drive positive shade positioning low wear low part count moving shade element remains substantially flat curving slightly phase positioning apparatus replaces conventional interior window panel manual shade slight change overall mechanism thickness weight control electronics shade accept command cabin attendant console override local setting move shade required position fully open takeoff shade support use two independent shade made dimming transparent diffusing translucent light blocking opaque material shade compatible electrochromic transmittance control technology,-1
